<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Daily Articles</title>
  
  <meta property="description" itemprop="description" content="There are 60 articles published today."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-12-18"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-12-18"/>
  <meta name="article:author" content="Nora Jones"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Daily Articles"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="There are 60 articles published today."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Daily Articles"/>
  <meta property="twitter:description" content="There are 60 articles published today."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Daily Articles"]},{"type":"character","attributes":{},"value":["There are 60 articles published today.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Nora Jones"]},{"type":"character","attributes":{},"value":["https://example.com/norajones"]}]}]},{"type":"character","attributes":{},"value":["2019-12-18"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["arxiv.csv","news_files/bowser-1.9.3/bowser.min.js","news_files/crosstalk-1.0.0/css/crosstalk.css","news_files/crosstalk-1.0.0/js/crosstalk.js","news_files/crosstalk-1.0.0/js/crosstalk.js.map","news_files/crosstalk-1.0.0/js/crosstalk.min.js","news_files/crosstalk-1.0.0/js/crosstalk.min.js.map","news_files/datatables-binding-0.4/css/datatables-crosstalk.css","news_files/datatables-binding-0.4/datatables.js","news_files/datatables-binding-0.4/datatables.yaml","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/dataTables.autoFill.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.colVis.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.flash.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.html5.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.print.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/dataTables.buttons.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/jszip.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/pdfmake.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/vfs_fonts.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/swf/flashExport.swf","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/js/dataTables.colReorder.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/js/dataTables.fixedColumns.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/js/dataTables.fixedHeader.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/js/dataTables.keyTable.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/dataTables.responsive.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/js/dataTables.rowGroup.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/js/dataTables.rowReorder.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/js/dataTables.scroller.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/js/dataTables.select.min.js","news_files/datatables-binding-0.4/lib/datatables-plugins/natural/natural.js","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/dataTables.searchHighlight.css","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/dataTables.searchHighlight.min.js","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/jquery.highlight.js","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap.extra.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.material.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.uikit.min.css","news_files/datatables-binding-0.4/lib/datatables/css/jquery.dataTables.extra.css","news_files/datatables-binding-0.4/lib/datatables/css/jquery.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.material.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.uikit.min.js","news_files/datatables-binding-0.4/lib/datatables/js/jquery.dataTables.min.js","news_files/datatables-binding-0.4/lib/datatables/license.txt","news_files/datatables-binding-0.4/lib/jquery/jquery.min.js","news_files/datatables-binding-0.4/lib/jquery/LICENSE.txt","news_files/datatables-binding-0.4/lib/nouislider/jquery.nouislider.min.css","news_files/datatables-binding-0.4/lib/nouislider/jquery.nouislider.min.js","news_files/datatables-binding-0.4/lib/selectize/selectize.bootstrap3.css","news_files/datatables-binding-0.4/lib/selectize/selectize.min.js","news_files/datatables-css-0.0.0/datatables-crosstalk.css","news_files/distill-2.2.21/template.v2.js","news_files/dt-core-1.10.16/css/jquery.dataTables.extra.css","news_files/dt-core-1.10.16/css/jquery.dataTables.min.css","news_files/dt-core-1.10.16/js/jquery.dataTables.min.js","news_files/htmlwidgets-1.2/htmlwidgets.js","news_files/jquery-1.11.3/jquery.min.js","news_files/jquery-1.12.4/jquery.min.js","news_files/jquery-1.12.4/LICENSE.txt","news_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="news_files/htmlwidgets-1.2/htmlwidgets.js"></script>
  <script src="news_files/jquery-1.12.4/jquery.min.js"></script>
  <link href="news_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
  <script src="news_files/datatables-binding-0.4/datatables.js"></script>
  <link href="news_files/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
  <link href="news_files/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
  <script src="news_files/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
  <link href="news_files/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
  <script src="news_files/crosstalk-1.0.0/js/crosstalk.min.js"></script>
  <script src="news_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="news_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="news_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Daily Articles","description":"There are 60 articles published today.","authors":[{"author":"Nora Jones","authorURL":"https://example.com/norajones","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-12-18T00:00:00.000-05:00","citationText":"Jones, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Daily Articles</h1>
<p>There are 60 articles published today.</p>
</div>

<div class="d-byline">
  Nora Jones <a href="https://example.com/norajones" class="uri">https://example.com/norajones</a> 
  
<br/>2019-12-18
</div>

<div class="d-article">
<div class="layout-chunk" data-layout="l-body">
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Category</th>
<th style="text-align: left;">arXiv Tag</th>
<th style="text-align: right;">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Computer Vision and Pattern Recognition</td>
<td style="text-align: left;">cs.CV</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="even">
<td style="text-align: left;">Machine Learning</td>
<td style="text-align: left;">cs.LG</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Computational Physics</td>
<td style="text-align: left;">physics.comp-ph</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">Image and Video Processing</td>
<td style="text-align: left;">eess.IV</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Machine Learning</td>
<td style="text-align: left;">stat.ML</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">Statistics Theory</td>
<td style="text-align: left;">math.ST</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Artificial Intelligence</td>
<td style="text-align: left;">cs.AI</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;">Methodology</td>
<td style="text-align: left;">stat.ME</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Computation and Language</td>
<td style="text-align: left;">cs.CL</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="even">
<td style="text-align: left;">Emerging Technologies</td>
<td style="text-align: left;">cs.ET</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Software Engineering</td>
<td style="text-align: left;">cs.SE</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="even">
<td style="text-align: left;">Applications</td>
<td style="text-align: left;">stat.AP</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Biomolecules</td>
<td style="text-align: left;">q-bio.BM</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Computation</td>
<td style="text-align: left;">stat.CO</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data Analysis, Statistics and Probability</td>
<td style="text-align: left;">physics.data-an</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">eess.SY</td>
<td style="text-align: left;">eess.SY</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Formal Languages and Automata Theory</td>
<td style="text-align: left;">cs.FL</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Human-Computer Interaction</td>
<td style="text-align: left;">cs.HC</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Information Theory</td>
<td style="text-align: left;">cs.IT</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Materials Science</td>
<td style="text-align: left;">cond-mat.mtrl-sci</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Medical Physics</td>
<td style="text-align: left;">physics.med-ph</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Multiagent Systems</td>
<td style="text-align: left;">cs.MA</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Numerical Analysis</td>
<td style="text-align: left;">math.NA</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Optimization and Control</td>
<td style="text-align: left;">math.OC</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Quantum Physics</td>
<td style="text-align: left;">quant-ph</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Robotics</td>
<td style="text-align: left;">cs.RO</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Signal Processing</td>
<td style="text-align: left;">eess.SP</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-page">
<div id="htmlwidget-05092e330e7de06a8816" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-05092e330e7de06a8816">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60"],["Artificial Agents Learn Flexible Visual Representations by Playing a\n  Hiding Game","Causality matters in medical imaging","Putting Ridesharing to the Test: Efficient and Scalable Solutions and\n  the Power of Dynamic Vehicle Relocation","A Novel Self-Organizing PID Approach for Controlling Mobile Robot\n  Locomotion","A Multi-task Learning Model for Chinese-oriented Aspect Polarity\n  Classification and Aspect Term Extraction","Pioneer dataset and automatic recognition of Urdu handwritten characters\n  using a deep autoencoder and convolutional neural network","Knowledge-Enhanced Attentive Learning for Answer Selection in Community\n  Question Answering Systems","Joint Interaction and Trajectory Prediction for Autonomous Driving using\n  Graph Neural Networks","Cross-Lingual Ability of Multilingual BERT: An Empirical Study","Design and Implementation of Linked Planning Domain Definition Language","ORC Layout: Adaptive GUI Layout with OR-Constraints","Balancing the Tradeoff Between Clustering Value and Interpretability","Angular Learning: Toward Discriminative Embedded Features","LTLf Synthesis with Fairness and Stability Assumptions","A Comprehensive Review of Shepherding as a Bio-inspired Swarm-Robotics\n  Guidance Approach","PointRend: Image Segmentation as Rendering","AeroRIT: A New Scene for Hyperspectral Image Analysis","Fast Glioblastoma Detection in Fluid-attenuated inversion recovery\n  (FLAIR) images by Topological Explainable Automatic Machine Learning","APRICOT: A Dataset of Physical Adversarial Attacks on Object Detection","Direction Concentration Learning: Enhancing Congruency in Machine\n  Learning","Improved Surrogates in Inertial Confinement Fusion with Manifold and\n  Cycle Consistencies","Feature Fusion Use Unsupervised Prior Knowledge to Let Small Object\n  Represent","Single-Stage Monocular 3D Object Detection with Virtual Cameras","Adaptive Densely Connected Super-Resolution Reconstruction","Jointly Trained Image and Video Generation using Residual Vectors","Conditional Generative ConvNets for Exemplar-based Texture Synthesis","Defects Mitigation in Resistive Crossbars for Analog Vector Matrix\n  Multiplication","Valley-Coupled-Spintronic Non-Volatile Memories with Compute-In-Memory\n  Support","Towards Smart Radio Environment for Wireless Communications via\n  Intelligent Reflecting Surfaces: A Comprehensive Survey","Supervised learning algorithms resilient to discriminatory data\n  perturbations","Deep Radar Waveform Design for Efficient Automotive Radar Sensing","Lift &amp; Learn: Physics-informed machine learning for large-scale\n  nonlinear dynamical systems","Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for\n  Python, C++, and soon more","Performance of regression models as a function of experiment noise","An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction","A learning-based algorithm to quickly compute good primal solutions for\n  Stochastic Integer Programs","HCNAF: Hyper-Conditioned Neural Autoregressive Flow and its Application\n  for Probabilistic Occupancy Map Forecasting","A Finite-Sample Deviation Bound for Stable Autoregressive Processes","Detection of a Source Code Plagiarism in a Student Programming\n  Competition","Probabilistic Software Modeling: A Data-driven Paradigm for Software\n  Analysis","Prema: A Tool for Precise Requirements Editing, Modeling and Analysis","Changing reference measure in Bayes spaces with applications to\n  functional data analysis","Weibull analysis with sequential order statistics under a power trend\n  model for hazard rates","Jackknife covariance matrix estimation for observations from mixture","Nonparametric density estimation for intentionally corrupted functional\n  data","Antiferromagnetic CuMnAs: Ab initio description of finite temperature\n  magnetism and resistivity","A multiscale discrete velocity method for model kinetic equations","Octopus, a computational framework for exploring light-driven phenomena\n  and quantum dynamics in extended and finite systems","QuESTlink -- Mathematica embiggened by a hardware-optimised quantum\n  emulator","Upper limit to the photovoltaic efficiency of imperfect crystals","Large-scale simulation of shallow water waves with computation only on\n  small staggered patches","Search in a fitness landscape: How to assess the difficulty of a search\n  problem","Spinal compressive forces in adolescent idiopathic scoliosis with and\n  without carrying loads: a musculoskeletal modeling study","Estimation of Residential Radon Concentration in Pennsylvania Counties\n  by Data Fusion","A nonparametric Bayesian approach to simultaneous subject and cell\n  heterogeneity discovery for single cell RNA-seq data","Multiple Change Point Detection and Validation in Autoregressive Time\n  Series Data","Optimality of Observed Information Adaptive Designs in Linear Models","Substitutes for the non-existent square lattice designs for 36 varieties","Sim-to-Real Domain Adaptation For High Energy Physics","Embedded Constrained Feature Construction for High-Energy Physics Data\n  Classification"],["The ubiquity of embodied gameplay, observed in a wide variety of animal\nspecies including turtles and ravens, has led researchers to question what\nadvantages play provides to the animals engaged in it. Mounting evidence\nsuggests that play is critical in developing the neural flexibility for\ncreative problem solving, socialization, and can improve the plasticity of the\nmedial prefrontal cortex. Comparatively little is known regarding the impact of\ngameplay upon embodied artificial agents. While recent work has produced\nartificial agents proficient in abstract games, the environments these agents\nact within are far removed the real world and thus these agents provide little\ninsight into the advantages of embodied play. Hiding games have arisen in\nmultiple cultures and species, and provide a rich ground for studying the\nimpact of embodied gameplay on representation learning in the context of\nperspective taking, secret keeping, and false belief understanding. Here we are\nthe first to show that embodied adversarial reinforcement learning agents\nplaying cache, a variant of hide-and-seek, in a high fidelity, interactive,\nenvironment, learn representations of their observations encoding information\nsuch as occlusion, object permanence, free space, and containment; on par with\nrepresentations learnt by the most popular modern paradigm for visual\nrepresentation learning which requires large datasets independently labeled for\neach new task. Our representations are enhanced by intent and memory, through\ninteraction and play, moving closer to biologically motivated learning\nstrategies. These results serve as a model for studying how facets of vision\nand perspective taking develop through play, provide an experimental framework\nfor assessing what is learned by artificial agents, and suggest that\nrepresentation learning should move from static datasets and towards\nexperiential, interactive, learning.","This article discusses how the language of causality can shed new light on\nthe major challenges in machine learning for medical imaging: 1) data scarcity,\nwhich is the limited availability of high-quality annotations, and 2) data\nmismatch, whereby a trained algorithm may fail to generalize in clinical\npractice. Looking at these challenges through the lens of causality allows\ndecisions about data collection, annotation procedures, and learning strategies\nto be made (and scrutinized) more transparently. We discuss how causal\nrelationships between images and annotations can not only have profound effects\non the performance of predictive models, but may even dictate which learning\nstrategies should be considered in the first place. For example, we conclude\nthat semi-supervision may be unsuitable for image segmentation---one of the\npossibly surprising insights from our causal analysis, which is illustrated\nwith representative real-world examples of computer-aided diagnosis (skin\nlesion classification in dermatology) and radiotherapy (automated contouring of\ntumours). We highlight that being aware of and accounting for the causal\nrelationships in medical imaging data is important for the safe development of\nmachine learning and essential for regulation and responsible reporting. To\nfacilitate this we provide step-by-step recommendations for future studies.","Ridesharing is a coordination problem in its core. Traditionally it has been\nsolved in a centralized manner by ridesharing platforms. Yet, to truly allow\nfor scalable solutions, we needs to shift from traditional approaches, to\nmulti-agent systems, ideally run on-device. In this paper, we show that a\nrecently proposed heuristic (ALMA), which exhibits such properties, offers an\nefficient, end-to-end solution for the ridesharing problem. Moreover, by\nutilizing simple relocation schemes we significantly improve QoS metrics, by up\nto 50%.\n  To demonstrate the latter, we perform a systematic evaluation of a diverse\nset of algorithms for the ridesharing problem, which is, to the best of our\nknowledge, one of the largest and most comprehensive to date. Our evaluation\nsetting is specifically designed to resemble reality as closely as possible. In\nparticular, we evaluate 12 different algorithms over 12 metrics related to\nglobal efficiency, complexity, passenger, driver, and platform incentives.","A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID)\ncontrol system is proposed in this paper. The proposed system consists of a\npair of control and reference models, both of which are implemented by a\nfirst-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. The\nSOF-PID controller self-organizes and self-updates the structures and\nmeta-parameters of both the control and reference models during the control\nprocess \"on the fly\". This gives the SOF-PID control system the capability of\nquickly adapting to entirely new operating environments without a full\nre-training. Moreover, the SOF-PID control system is free from user- and\nproblem-specific parameters, and the uniform stability of the SOF-PID control\nsystem is theoretically guaranteed. Simulations and real-world experiments with\nmobile robots demonstrate the effectiveness and validity of the proposed\nSOF-PID control system.","Aspect-based sentiment analysis (ABSA) task is a multi-grained task of\nnatural language processing and consists of two subtasks: aspect term\nextraction (ATE) and aspect polarity classification (APC). Most of the existing\nwork focuses on the subtask of aspect term polarity inferring and ignores the\nsignificance of aspect term extraction. Besides, the xisting researches do not\npay attention to the research of the Chinese-oriented ABSA task. Based on the\nlocal context focus (LCF) mechanism, this paper firstly proposes a multi-task\nlearning model for Chineseoriented aspect-based sentiment analysis, namely\nLCF-ATEPC. Compared with existing models, this model equips the capability of\nextracting aspect term and inferring aspect term polarity synchronously,\nmoreover, this model is effective to analyze both Chinese and English comments\nsimultaneously and the experiment on a multilingual mixed dataset proved its\navailability. By integrating the domain-adapted BERT model, the LCF-ATEPC model\nachieved the state-ofthe-art performance of aspect term extraction and aspect\npolarity classification in four Chinese review datasets. Besides, the\nexperimental results on the most commonly used SemEval-2014 task4 Restaurant\nand Laptop datasets outperform the state-of-the-art performance on the ATE\nsubtask.","Automatic recognition of Urdu handwritten digits and characters, is a\nchallenging task. It has applications in postal address reading, bank's cheque\nprocessing, and digitization and preservation of handwritten manuscripts from\nold ages. While there exists a significant work for automatic recognition of\nhandwritten English characters and other major languages of the world, the work\ndone for Urdu lan-guage is extremely insufficient. This paper has two goals.\nFirstly, we introduce a pioneer dataset for handwritten digits and characters\nof Urdu, containing samples from more than 900 individuals. Secondly, we report\nresults for automatic recog-nition of handwritten digits and characters as\nachieved by using deep auto-encoder network and convolutional neural network.\nMore specifically, we use a two-layer and a three-layer deep autoencoder\nnetwork and convolutional neural network and evaluate the two frameworks in\nterms of recognition accuracy. The proposed framework of deep autoencoder can\nsuccessfully recognize digits and characters with an accuracy of 97% for digits\nonly, 81% for characters only and 82% for both digits and characters\nsimultaneously. In comparison, the framework of convolutional neural network\nhas accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for\nboth digits and characters simultaneously. These frameworks can serve as\nbaselines for future research on Urdu handwritten text.","In the community question answering (CQA) system, the answer selection task\naims to identify the best answer for a specific question, and thus is playing a\nkey role in enhancing the service quality through recommending appropriate\nanswers for new questions. Recent advances in CQA answer selection focus on\nenhancing the performance by incorporating the community information,\nparticularly the expertise (previous answers) and authority (position in the\nsocial network) of an answerer. However, existing approaches for incorporating\nsuch information are limited in (a) only considering either the expertise or\nthe authority, but not both; (b) ignoring the domain knowledge to differentiate\ntopics of previous answers; and (c) simply using the authority information to\nadjust the similarity score, instead of fully utilizing it in the process of\nmeasuring the similarity between segments of the question and the answer. We\npropose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which\nenhances the performance through (a) considering both the expertise and the\nauthority of the answerer; (b) utilizing the human-labeled tags, the taxonomy\nof the tags, and the votes as the domain knowledge to infer the expertise of\nthe answer; (c) using matrix decomposition of the social network (formed by\nfollowing-relationship) to infer the authority of the answerer and\nincorporating such information in the process of evaluating the similarity\nbetween segments. Besides, for vertical community, we incorporate an external\nknowledge graph to capture more professional information for vertical CQA\nsystems. Then we adopt the attention mechanism to integrate the analysis of the\ntext of questions and answers and the aforementioned community information.\nExperiments with both vertical and general CQA sites demonstrate the superior\nperformance of the proposed KAAS model.","In this work, we aim to predict the future motion of vehicles in a traffic\nscene by explicitly modeling their pairwise interactions. Specifically, we\npropose a graph neural network that jointly predicts the discrete interaction\nmodes and 5-second future trajectories for all agents in the scene. Our model\ninfers an interaction graph whose nodes are agents and whose edges capture the\nlong-term interaction intents among the agents. In order to train the model to\nrecognize known modes of interaction, we introduce an auto-labeling function to\ngenerate ground truth interaction labels. Using a large-scale real-world\ndriving dataset, we demonstrate that jointly predicting the trajectories along\nwith the explicit interaction types leads to significantly lower trajectory\nerror than baseline methods. Finally, we show through simulation studies that\nthe learned interaction modes are semantically meaningful.","Recent work has exhibited the surprising cross-lingual abilities of\nmultilingual BERT (M-BERT) -- surprising since it is trained without any\ncross-lingual objective and with no aligned data. In this work, we provide a\ncomprehensive study of the contribution of different components in M-BERT to\nits cross-lingual ability. We study the impact of linguistic properties of the\nlanguages, the architecture of the model, and the learning objectives. The\nexperimental study is done in the context of three typologically different\nlanguages -- Spanish, Hindi, and Russian -- and using two conceptually\ndifferent NLP tasks, textual entailment and named entity recognition. Among our\nkey conclusions is the fact that the lexical overlap between languages plays a\nnegligible role in the cross-lingual success, while the depth of the network is\nan integral part of it.","Planning is a critical component of any artificial intelligence system that\nconcerns the realization of strategies or action sequences typically for\nintelligent agents and autonomous robots. Given predefined parameterized\nactions, a planning service should accept a query with the goal and initial\nstate to give a solution with a sequence of actions applied to environmental\nobjects. This paper addresses the problem by providing a repository of actions\ngenerically applicable to various environmental objects based on Semantic Web\ntechnologies. Ontologies are used for asserting constraints in common sense as\nwell as for resolving compatibilities between actions and states. Constraints\nare defined using Web standards such as SPARQL and SHACL to allow conditional\npredicates. We demonstrate the usefulness of the proposed planning domain\ndescription language with our robotics applications.","We propose a novel approach for constraint-based graphical user interface\n(GUI) layout based on OR-constraints (ORC) in standard soft/hard linear\nconstraint systems. ORC layout unifies grid layout and flow layout, supporting\nboth their features as well as cases where grid and flow layouts individually\nfail. We describe ORC design patterns that enable designers to safely create\nflexible layouts that work across different screen sizes and orientations. We\nalso present the ORC Editor, a GUI editor that enables designers to apply ORC\nin a safe and effective manner, mixing grid, flow and new ORC layout features\nas appropriate. We demonstrate that our prototype can adapt layouts to screens\nwith different aspect ratios with only a single layout specification, easing\nthe burden of GUI maintenance. Finally, we show that ORC specifications can be\nmodified interactively and solved efficiently at runtime.","Graph clustering groups entities -- the vertices of a graph -- based on their\nsimilarity, typically using a complex distance function over a large number of\nfeatures. Successful integration of clustering approaches in automated\ndecision-support systems hinges on the interpretability of the resulting\nclusters. This paper addresses the problem of generating interpretable\nclusters, given features of interest that signify interpretability to an\nend-user, by optimizing interpretability in addition to common clustering\nobjectives. We propose a $\\beta$-interpretable clustering algorithm that\nensures that at least $\\beta$ fraction of nodes in each cluster share the same\nfeature value. The tunable parameter $\\beta$ is user-specified. We also present\na more efficient algorithm for scenarios with $\\beta\\!=\\!1$ and analyze the\ntheoretical guarantees of the two algorithms. Finally, we empirically\ndemonstrate the benefits of our approaches in generating interpretable clusters\nusing four real-world datasets. The interpretability of the clusters is\ncomplemented by generating simple explanations denoting the feature values of\nthe nodes in the clusters, using frequent pattern mining.","The margin-based softmax loss functions greatly enhance intra-class\ncompactness and perform well on the tasks of face recognition and object\nclassification. Outperformance, however, depends on the careful hyperparameter\nselection. Moreover, the hard angle restriction also increases the risk of\noverfitting. In this paper, angular loss suggested by maximizing the angular\ngradient to promote intra-class compactness avoids overfitting. Besides, our\nmethod has only one adjustable constant for intra-class compactness control. We\ndefine three metrics to measure inter-class separability and intra-class\ncompactness. In experiments, we test our method, as well as other methods, on\nmany well-known datasets. Experimental results reveal that our method has the\nsuperiority of accuracy improvement, discriminative information, and\ntime-consumption.","In synthesis, assumptions are constraints on the environment that rule out\ncertain environment behaviors. A key observation here is that even if we\nconsider systems with LTLf goals on finite traces, environment assumptions need\nto be expressed over infinite traces, since accomplishing the agent goals may\nrequire an unbounded number of environment action. To solve synthesis with\nrespect to finite-trace LTLf goals under infinite-trace assumptions, we could\nreduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and\nin LTL have the same worst-case complexity (both 2EXPTIME-complete), the\nalgorithms available for LTL synthesis are much more difficult in practice than\nthose for LTLf synthesis. In this work we show that in interesting cases we can\navoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis.\nSpecifically, we develop a BDD-based fixpoint-based technique for handling\nbasic forms of fairness and of stability assumptions. We show, empirically,\nthat this technique performs much better than standard LTL synthesis.","The simultaneous control of multiple coordinated robotic agents represents an\nelaborate problem. If solved, however, the interaction between the agents can\nlead to solutions to sophisticated problems. The concept of swarming, inspired\nby nature, can be described as the emergence of complex system-level behaviors\nfrom the interactions of relatively elementary agents. Due to the effectiveness\nof solutions found in nature, bio-inspired swarming-based control techniques\nare receiving a lot of attention in robotics. One method, known as swarm\nshepherding, is founded on the sheep herding behavior exhibited by sheepdogs,\nwhere a swarm of relatively simple agents are governed by a shepherd (or\nshepherds) which is responsible for high-level guidance and planning. Many\nstudies have been conducted on shepherding as a control technique, ranging from\nthe replication of sheep herding via simulation, to the control of uninhabited\nvehicles and robots for a variety of applications. We present a comprehensive\nreview of the literature on swarm shepherding to reveal the advantages and\npotential of the approach to be applied to a plethora of robotic systems in the\nfuture.","We present a new method for efficient high-quality image segmentation of\nobjects and scenes. By analogizing classical computer graphics methods for\nefficient rendering with over- and undersampling challenges faced in pixel\nlabeling tasks, we develop a unique perspective of image segmentation as a\nrendering problem. From this vantage, we present the PointRend (Point-based\nRendering) neural network module: a module that performs point-based\nsegmentation predictions at adaptively selected locations based on an iterative\nsubdivision algorithm. PointRend can be flexibly applied to both instance and\nsemantic segmentation tasks by building on top of existing state-of-the-art\nmodels. While many concrete implementations of the general idea are possible,\nwe show that a simple design already achieves excellent results. Qualitatively,\nPointRend outputs crisp object boundaries in regions that are over-smoothed by\nprevious methods. Quantitatively, PointRend yields significant gains on COCO\nand Cityscapes, for both instance and semantic segmentation. PointRend's\nefficiency enables output resolutions that are otherwise impractical in terms\nof memory or computation compared to existing approaches.","Hyperspectral imagery oriented research like image super-resolution and image\nfusion is often conducted on open source datasets captured via point and shoot\ncamera setups (ICVL, CAVE) that have high signal to noise ratio. In contrast,\nspectral images captured from aircrafts have low spatial resolution and suffer\nfrom higher noise interference due to factors pertaining to atmospheric\nconditions. This leads to challenges in extracting contextual information from\nthe captured data as convolutional neural networks are very noise-sensitive and\nslight atmospheric changes can often lead to a large distribution spread in\nspectral values overlooking the same object.\n  To understand the challenges faced with aerial spectral data, we collect and\nlabel a flight line over the university campus, AeroRIT, and explore the task\nof semantic segmentation. To the best of our knowledge, this is the first\ncomprehensive large-scale hyperspectral scene with nearly seven million\nsemantic annotations for identifying cars, roads and buildings. We compare the\nperformance of three popular architectures - SegNet, U-Net and Res-U-Net, for\nscene understanding and object identification. To date, aerial hyperspectral\nimage analysis has been restricted to small datasets with limited train/test\nsplits capabilities. We believe AeroRIT will help advance the research in the\nfield with a more complex object distribution.","Glioblastoma multiforme (GBM) is a fast-growing and highly invasive brain\ntumor, it tends to occur in adults between the ages of 45 and 70 and it\naccounts for 52 percent of all primary brain tumors. Usually, GBMs are detected\nby magnetic resonance images (MRI). Among MRI images, Fluid-attenuated\ninversion recovery (FLAIR) sequence produces high quality digital tumor\nrepresentation. This sequence is very sensitive to pathology and makes the\ndifferentiation between cerebrospinal fluid (CSF) and an abnormality much\neasier. Fast detection and segmentation techniques are needed for overcoming\nsubjective medical doctors (MDs) judgment. In this work, a new methodology for\nfast detection and segmentation of GBM on FLAIR images is presented. The\nmethodology leverages topological data analysis, textural features and\ninterpretable machine learning algorithm, it was evaluated on a public\navailable dataset. The machine learning classifier uses only eight input\nnumerical features and it reaches up to the 97% of accuracy on the detection\ntask and up to 95% of accuracy on the segmentation task. Tools from information\ntheory were used for interpreting, in a human readable format, what are the\nmain numerical characteristics of an image to be classified ill or healthy.","Physical adversarial attacks threaten to fool object detection systems, but\nreproducible research on the real-world effectiveness of physical patches and\nhow to defend against them requires a publicly available benchmark dataset. We\npresent APRICOT, a collection of over 1,000 annotated photographs of printed\nadversarial patches in public locations. The patches target several object\ncategories for three COCO-trained detection models, and the photos represent\nnatural variation in position, distance, lighting conditions, and viewing\nangle. Our analysis suggests that maintaining adversarial robustness in\nuncontrolled settings is highly challenging, but it is still possible to\nproduce targeted detections under white-box and sometimes black-box settings.\nWe establish baselines for defending against adversarial patches through\nseveral methods, including a detector supervised with synthetic data and\nunsupervised methods such as kernel density estimation, Bayesian uncertainty,\nand reconstruction error. Our results suggest that adversarial patches can be\neffectively flagged, both in a high-knowledge, attack-specific scenario, and in\nan unsupervised setting where patches are detected as anomalies in natural\nimages. This dataset and the described experiments provide a benchmark for\nfuture research on the effectiveness of and defenses against physical\nadversarial objects in the wild.","One of the well-known challenges in computer vision tasks is the visual\ndiversity of images, which could result in an agreement or disagreement between\nthe learned knowledge and the visual content exhibited by the current\nobservation. In this work, we first define such an agreement in a concepts\nlearning process as congruency. Formally, given a particular task and\nsufficiently large dataset, the congruency issue occurs in the learning process\nwhereby the task-specific semantics in the training data are highly varying. We\npropose a Direction Concentration Learning (DCL) method to improve congruency\nin the learning process, where enhancing congruency influences the convergence\npath to be less circuitous. The experimental results show that the proposed DCL\nmethod generalizes to state-of-the-art models and optimizers, as well as\nimproves the performances of saliency prediction task, continual learning task,\nand classification task. Moreover, it helps mitigate the catastrophic\nforgetting problem in the continual learning task. The code is publicly\navailable at https://github.com/luoyan407/congruency.","Neural networks have become very popular in surrogate modeling because of\ntheir ability to characterize arbitrary, high dimensional functions in a data\ndriven fashion. This paper advocates for the training of surrogates that are\nconsistent with the physical manifold -- i.e., predictions are always\nphysically meaningful, and are cyclically consistent -- i.e., when the\npredictions of the surrogate, when passed through an independently trained\ninverse model give back the original input parameters. We find that these two\nconsistencies lead to surrogates that are superior in terms of predictive\nperformance, more resilient to sampling artifacts, and tend to be more data\nefficient. Using Inertial Confinement Fusion (ICF) as a test bed problem, we\nmodel a 1D semi-analytic numerical simulator and demonstrate the effectiveness\nof our approach. Code and data are available at\nhttps://github.com/rushilanirudh/macc/","Fusing low level and high level features is a widely used strategy to provide\ndetails that might be missing during convolution and pooling. Different from\nprevious works, we propose a new fusion mechanism called FillIn which takes\nadvantage of prior knowledge described with superpixel segmentation. According\nto the prior knowledge, the FillIn chooses small region on low level feature\nmap to fill into high level feature map. By using the proposed fusion\nmechanism, the low level features have equal channels for some tiny region as\nhigh level features, which makes the low level features have relatively\nindependent power to decide final semantic label. We demonstrate the\neffectiveness of our model on PASCAL VOC 2012, it achieves competitive test\nresult based on DeepLabv3+ backbone and visualizations of predictions prove our\nfusion can let small objects represent and low level features have potential\nfor segmenting small objects.","While expensive LiDAR and stereo camera rigs have enabled the development of\nsuccessful 3D object detection methods, monocular RGB-only approaches still lag\nsignificantly behind. Our work advances the state of the art by introducing\nMoVi-3D, a novel, single-stage deep architecture for monocular 3D object\ndetection. At its core, MoVi-3D leverages geometrical information to generate\nsynthetic views from virtual cameras at both, training and test time, resulting\nin normalized object appearance with respect to distance. Our synthetically\ngenerated views facilitate the detection task as they cut down the variability\nin visual appearance associated to objects placed at different distances from\nthe camera. As a consequence, the deep model is relieved from learning\ndepth-specific representations and its complexity can be significantly reduced.\nIn particular we show that our proposed concept of exploiting virtual cameras\nenables us to set new state-of-the-art results on the popular KITTI3D benchmark\nusing just a lightweight, single-stage architecture.","For a better performance in single image super-resolution(SISR), we present\nan image super-resolution algorithm based on adaptive dense connection (ADCSR).\nThe algorithm is divided into two parts: BODY and SKIP. BODY improves the\nutilization of convolution features through adaptive dense connections. Also,\nwe develop an adaptive sub-pixel reconstruction layer (AFSL) to reconstruct the\nfeatures of the BODY output. We pre-trained SKIP to make BODY focus on\nhigh-frequency feature learning. The comparison of PSNR, SSIM, and visual\neffects verify the superiority of our method to the state-of-the-art\nalgorithms.","In this work, we propose a modeling technique for jointly training image and\nvideo generation models by simultaneously learning to map latent variables with\na fixed prior onto real images and interpolate over images to generate videos.\nThe proposed approach models the variations in representations using residual\nvectors encoding the change at each time step over a summary vector for the\nentire video. We utilize the technique to jointly train an image generation\nmodel with a fixed prior along with a video generation model lacking\nconstraints such as disentanglement. The joint training enables the image\ngenerator to exploit temporal information while the video generation model\nlearns to flexibly share information across frames. Moreover, experimental\nresults verify our approach's compatibility with pre-training on videos or\nimages and training on datasets containing a mixture of both. A comprehensive\nset of quantitative and qualitative evaluations reveal the improvements in\nsample quality and diversity over both video generation and image generation\nbaselines. We further demonstrate the technique's capabilities of exploiting\nsimilarity in features across frames by applying it to a model based on\ndecomposing the video into motion and content. The proposed model allows minor\nvariations in content across frames while maintaining the temporal dependence\nthrough latent vectors encoding the pose or motion features.","The goal of exemplar-based texture synthesis is to generate texture images\nthat are visually similar to a given exemplar. Recently, promising results have\nbeen reported by methods relying on convolutional neural networks (ConvNets)\npretrained on large-scale image datasets. However, these methods have\ndifficulties in synthesizing image textures with non-local structures and\nextending to dynamic or sound textures. In this paper, we present a conditional\ngenerative ConvNet (cgCNN) model which combines deep statistics and the\nprobabilistic framework of generative ConvNet (gCNN) model. Given a texture\nexemplar, the cgCNN model defines a conditional distribution using deep\nstatistics of a ConvNet, and synthesize new textures by sampling from the\nconditional distribution. In contrast to previous deep texture models, the\nproposed cgCNN dose not rely on pre-trained ConvNets but learns the weights of\nConvNets for each input exemplar instead. As a result, the cgCNN model can\nsynthesize high quality dynamic, sound and image textures in a unified manner.\nWe also explore the theoretical connections between our model and other texture\nmodels. Further investigations show that the cgCNN model can be easily\ngeneralized to texture expansion and inpainting. Extensive experiments\ndemonstrate that our model can achieve better or at least comparable results\nthan the state-of-the-art methods.","With storage and computation happening at the same place, computing in\nresistive crossbars minimizes data movement and avoids the memory bottleneck\nissue. It leads to ultra-high energy efficiency for data-intensive\napplications. However, defects in crossbars severely affect computing accuracy.\nExisting solutions, including re-training with defects and redundant designs,\nbut they have limitations in practical implementations. In this work, we\nintroduce row shuffling and output compensation to mitigate defects without\nre-training or redundant resistive crossbars. We also analyzed the coupling\neffects of defects and circuit parasitics. Moreover, We study different\ncombinations of methods to achieve the best trade-off between cost and\nperformance. Our proposed methods could rescue up to 10% of defects in\nResNet-20 application without performance degradation.","In this work, we propose valley-coupled spin-hall memories (VSH-MRAMs) based\non monolayer WSe2. The key features of the proposed memories are (a) the\nability to switch magnets with perpendicular magnetic anisotropy (PMA) via VSH\neffect and (b) an integrated gate that can modulate the charge/spin current\n(IC/IS) flow. The former attribute results in high energy efficiency (compared\nto the Giant-Spin Hall (GSH) effect-based devices with in-plane magnetic\nanisotropy (IMA) magnets). The latter feature leads to a compact access\ntransistor-less memory array design. We experimentally measure the gate\ncontrollability of the current as well as the nonlocal resistance associated\nwith VSH effect. Based on the measured data, we develop a simulation framework\n(using physical equations) to propose and analyze single-ended and differential\nVSH effect based magnetic memories (VSH-MRAM and DVSH-MRAM, respectively). At\nthe array level, the proposed VSH/DVSH-MRAMs achieve 50%/ 11% lower write time,\n59%/ 67% lower write energy and 35%/ 41% lower read energy at iso-sense margin,\ncompared to single ended/differential (GSH/DGSH)-MRAMs. System level evaluation\nin the context of general purpose processor and intermittently-powered system\nshows up to 3.14X and 1.98X better energy efficiency for the proposed\n(D)VSH-MRAMs over (D)GSH-MRAMs respectively. Further, the differential sensing\nof the proposed DVSH-MRAM leads to natural and simultaneous in-memory\ncomputation of bit-wise AND and NOR logic functions. Using this feature, we\ndesign a computation-in-memory (CiM) architecture that performs Boolean logic\nand addition (ADD) with a single array access. System analysis performed by\nintegrating our DVSH-MRAM: CiM in the Nios II processor across various\napplication benchmarks shows up to 2.66X total energy savings, compared to\nDGSH-MRAM: CiM.","This paper presents a comprehensive literature review on applications and\ndesign aspects of the intelligent reflecting surface (IRS) in the future\nwireless networks. Conventionally, the network optimization has been limited to\ntransmission control at two endpoints, i.e., end users and network controller.\nThe fading wireless channel is uncontrollable and becomes one of the main\nlimiting factors for performance improvement. The IRS is composed of a large\narray of scattering elements, which can be individually configured to generate\nadditional phase shifts to the signal reflections. Hence, it can actively\ncontrol the signal propagation properties in favor of signal reception, and\nthus realize the notion of a smart radio environment. As such, the IRS's phase\ncontrol combined with the conventional transmission control can potentially\nbring performance gain compared to the conventional wireless networks without\nusing the IRS. In this survey, we first introduce basic concepts of the IRS and\nthe realizations of its reconfigurability. Then, we focus on applications of\nthe IRS in wireless communications. We overview different performance metrics\nand analytical approaches to characterize the performance improvement of\nIRS-assisted wireless networks. To exploit the performance gain, we discuss the\njoint optimization of the IRS's phase control and the transceivers'\ntransmission control in different network design problems, e.g., rate\nmaximization and power minimization problems. Furthermore, we extend the\ndiscussion of IRS-assisted wireless networks to some emerging wireless\napplications. Finally, we highlight important practical challenges and future\nresearch directions of realizing IRS-assisted wireless communications in beyond\n5G networks.","The actions of individuals can be discriminatory with respect to certain\nprotected attributes, such as race or sex. Recently, discrimination has become\na focal concern in supervised learning algorithms augmenting human\ndecision-making. These systems are trained using historical data, which may\nhave been tainted by discrimination, and may learn biases against the protected\ngroups. An important question is how to train models without propagating\ndiscrimination. Such discrimination can be either direct, when one or more of\nprotected attributes are used in the decision-making directly, or indirect,\nwhen other attributes correlated with the protected attributes are used in an\nunjustified manner. In this work, we i) model discrimination as a perturbation\nof data-generating process; ii) introduce a measure of resilience of a\nsupervised learning algorithm to potentially discriminatory data perturbations;\nand iii) propose a novel supervised learning method that is more resilient to\nsuch discriminatory perturbations than state-of-the-art learning algorithms\naddressing discrimination. The proposed method can be used with general\nsupervised learning algorithms, prevents direct discrimination and avoids\ninducement of indirect discrimination, while maximizing model accuracy.","In radar systems, unimodular (or constant-modulus) waveform design plays an\nimportant role in achieving better clutter/interference rejection, as well as a\nmore accurate estimation of the target parameters. The design of such sequences\nhas been studied widely in the last few decades, with most design algorithms\nrequiring sophisticated a priori knowledge of environmental parameters which\nmay be difficult to obtain in real-time scenarios. In this paper, we propose a\nnovel hybrid model-driven and data-driven architecture that adapts to the ever\nchanging environment and allows for adaptive unimodular waveform design. In\nparticular, the approach lays the groundwork for developing extremely low-cost\nwaveform design and processing frameworks for radar systems deployed in\nautonomous vehicles. The proposed model-based deep architecture imitates a\nwell-known unimodular signal design algorithm in its structure, and can quickly\ninfer statistical information from the environment using the observed data. Our\nnumerical experiments portray the advantages of using the proposed method for\nefficient radar waveform design in time-varying environments.","We present Lift &amp; Learn, a physics-informed method for learning\nlow-dimensional models for large-scale dynamical systems. The method exploits\nknowledge of a system's governing equations to identify a coordinate\ntransformation in which the system dynamics have quadratic structure. This\ntransformation is called a lifting map because it often adds auxiliary\nvariables to the system state. The lifting map is applied to data obtained by\nevaluating a model for the original nonlinear system. This lifted data is\nprojected onto its leading principal components, and low-dimensional linear and\nquadratic matrix operators are fit to the lifted reduced data using a\nleast-squares operator inference procedure. Analysis of our method shows that\nthe Lift &amp; Learn models are able to capture the system physics in the lifted\ncoordinates at least as accurately as traditional intrusive model reduction\napproaches. This preservation of system physics makes the Lift &amp; Learn models\nrobust to changes in inputs. Numerical experiments on the FitzHugh-Nagumo\nneuron activation model and the compressible Euler equations demonstrate the\ngeneralizability of our model.","Cyanure is an open-source C++ software package with a Python interface. The\ngoal of Cyanure is to provide state-of-the-art solvers for learning linear\nmodels, based on stochastic variance-reduced stochastic optimization with\nacceleration mechanisms. Cyanure can handle a large variety of loss functions\n(logistic, square, squared hinge, multinomial logistic) and regularization\nfunctions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It\nprovides a simple Python API, which is very close to that of scikit-learn,\nwhich should be extended to other languages such as R or Matlab in a near\nfuture.","A challenge in developing machine learning regression models is that it is\ndifficult to know whether maximal performance has been reached on a particular\ndataset, or whether further model improvement is possible. In biology this\nproblem is particularly pronounced as sample labels are typically obtained\nthrough experiments and therefore have experiment noise associated with them.\nSuch label noise puts a fundamental limit to the performance attainable by\nregression models. We address this challenge by deriving a theoretical upper\nbound for the coefficient of determination (R2) for regression models. This\ntheoretical upper bound depends only on the noise associated with sample labels\nin a dataset as well as the label variance. The upper bound estimate was\nvalidated via Monte Carlo simulations and then used as a tool to bootstrap\nperformance of regression models trained on biological datasets, including\nprotein sequence data, transcriptomic data, and genomic data. Although we study\nbiological datasets in this work, the new upper bound estimates will hold true\nfor regression models from any research field or application area where sample\nlabels are associated with noise.","The goal of eXtreme Multi-label Learning (XML) is to design and learn a model\nthat can automatically annotate a given data point with the most relevant\nsubset of labels from an extremely large label set. Recently, many techniques\nhave been proposed for XML that achieve reasonable performance on benchmark\ndatasets. Motivated by the complexities of these methods and their subsequent\ntraining requirements, in this paper we propose a simple baseline technique for\nthis task. Precisely, we present a global feature embedding technique for XML\nthat can easily scale to very large datasets containing millions of data points\nin very high-dimensional feature space, irrespective of number of samples and\nlabels. Next we show how an ensemble of such global embeddings can be used to\nachieve further boost in prediction accuracies with only linear increase in\ntraining and prediction time. During testing, we assign the labels using a\nweighted k-nearest neighbour classifier in the embedding space. Experiments\nreveal that though conceptually simple, this technique achieves quite\ncompetitive results, and has training time of less than one minute using a\nsingle CPU core with 15.6 GB RAM even for large-scale datasets such as\nAmazon-3M.","We propose a novel approach using supervised learning to obtain near-optimal\nprimal solutions for two-stage stochastic integer programming (2SIP) problems\nwith constraints in the first and second stages. The goal of the algorithm is\nto predict a \"representative scenario\" (RS) for the problem such that,\ndeterministically solving the 2SIP with the random realization equal to the RS,\ngives a near-optimal solution to the original 2SIP. Predicting an RS, instead\nof directly predicting a solution ensures first-stage feasibility of the\nsolution. If the problem is known to have complete recourse, second-stage\nfeasibility is also guaranteed. For computational testing, we learn to find an\nRS for a two-stage stochastic facility location problem with integer variables\nand linear constraints in both stages and consistently provide near-optimal\nsolutions. Our computing times are very competitive with those of\ngeneral-purpose integer programming solvers to achieve a similar solution\nquality.","We introduce Hyper-Conditioned Neural Autoregressive Flow (HCNAF); a powerful\nuniversal distribution approximator designed to model arbitrarily complex\nconditional probability density functions. HCNAF consists of a neural-net based\nconditional autoregressive flow (AF) and a hyper-network that can take large\nconditions in non-autoregressive fashion and outputs the network parameters of\nthe AF. Like other flow models, HCNAF performs exact likelihood inference. We\ndemonstrate the effectiveness and attributes of HCNAF, including its\ngeneralization capability over unseen conditions and show that HCNAF\noutperforms recent AF models in a conditional density estimation task for\nMNIST. We also show that HCNAF scales up to complex high-dimensional prediction\nproblems of the magnitude of self-driving and that HCNAF yields a\nstate-of-the-art performance in a public self-driving dataset.","In this paper, we study non-asymptotic deviation bounds of the least squares\nestimator in Gaussian AR($n$) processes. By relying on martingale concentration\ninequalities and a tail-bound for $\\chi^2$ distributed variables, we provide a\nconcentration bound for the sample covariance matrix of the process output.\nWith this, we present a problem-dependent finite-time bound on the deviation\nprobability of any fixed linear combination of the estimated parameters of the\nAR$(n)$ process. We discuss extensions and limitations of our approach.","The article presents a system for testing the independence of solutions to\nalgorithmic problems sent by students as part of the student programming\ncompetition. First, the context was discussed, as well as the need to organize\nprogramming competitions resulting from this context. Then, an algorithm was\nproposed to study the mutual similarity of source codes of programs sent as\npart of a programming competition. Since, after implementation, the algorithm\nwas used in practice, examples of its application for detecting the plagiarism\nof source codes of solutions in two programming competitions conducted as part\nof classes on Algorithms and Numerical Methods were also presented. Finally,\nthe effectiveness of the solutions used in the work was discussed.","Software systems are complex, and behavioral comprehension with the\nincreasing amount of AI components challenges traditional testing and\nmaintenance strategies.The lack of tools and methodologies for behavioral\nsoftware comprehension leaves developers to testing and debugging that work in\nthe boundaries of known scenarios. We present Probabilistic Software Modeling\n(PSM), a data-driven modeling paradigm for predictive and generative methods in\nsoftware engineering. PSM analyzes a program and synthesizes a network of\nprobabilistic models that can simulate and quantify the original program's\nbehavior. The approach extracts the type, executable, and property structure of\na program and copies its topology. Each model is then optimized towards the\nobserved runtime leading to a network that reflects the system's structure and\nbehavior. The resulting network allows for the full spectrum of statistical\ninferential analysis with which rich predictive and generative applications can\nbe built. Applications range from the visualization of states, inferential\nqueries, test case generation, and anomaly detection up to the stochastic\nexecution of the modeled system. In this work, we present the modeling\nmethodologies, an empirical study of the runtime behavior of software systems,\nand a comprehensive study on PSM modeled systems. Results indicate that PSM is\na solid foundation for structural and behavioral software comprehension\napplications.","We present Prema, a tool for Precise Requirement Editing, Modeling and\nAnalysis. It can be used in various fields for describing precise requirements\nusing formal notations and performing rigorous analysis. By parsing the\nrequirements written in formal modeling language, Prema is able to get a model\nwhich aptly depicts the requirements. It also provides different rigorous\nverification and validation techniques to check whether the requirements meet\nusers' expectation and find potential errors. We show that our tool can provide\na unified environment for writing and verifying requirements without using\ntools that are not well inter-related. For experimental demonstration, we use\nthe requirements of the automatic train protection (ATP) system of CASCO signal\nco. LTD., the largest railway signal control system manufacturer of China. The\ncode of the tool cannot be released here because the project is commercially\nconfidential. However, a demonstration video of the tool is available at\nhttps://youtu.be/BX0yv8pRMWs.","Probability density functions (PDFs) can be understood as continuous\ncompositions by the theory of Bayes spaces. The origin of a Bayes space is\ndetermined by a given reference measure. This can be easily changed through the\nwell-known chain rule which has an impact on the geometry of the Bayes space.\nThis work provides a mathematical framework for setting a reference measure. It\nis used to develop a weighting scheme on the bounded domain of distributional\ndata. The impact on statistical analysis is shown from the perspective of\nsimplicial functional principal component analysis. Moreover, a novel centered\nlog-ratio transformation is proposed to map a weighted Bayes spaces into an\nunweighted $L^2$ space, enabling to use most tools developed in functional data\nanalysis (e.g. clustering, regression analysis, etc.) while accounting for the\nweighting strategy. The potential of our proposal is shown through simulation\nand on a real case study using Italian income data.","In engineering systems, it is usually assumed that lifetimes of components\nare independent and identically distributed (iid). But, the failure of a\ncomponent results in a higher load on the remaining components and hence causes\nthe distribution of the surviving components change. For modeling this kind of\nsystems, the theory of sequential order statistics (SOS) can be used. Assuming\nWeibull distribution for lifetimes of components and conditionally proportional\nhazard rates model as a special case of the SOS theory, the maximum likelihood\nestimates of the unknown parameters are obtained in different cases. A new\nmodel, denoted by PTCPHM, as a generalization of the iid case is proposed, and\nthen statistical inferential methods including point and interval estimation as\nwell as hypothesis tests under PTCPHM are then developed. Finally, a real data\non failure times of aircraft components, due to Mann and Fertig (1973), is\nanalyzed to illustrate the model and inferential methods developed here.","A general jackknife estimator for the asymptotic covariance of moment\nestimators is considered in the case when the sample is taken from a mixture\nwith varying concentrations of components. Consistency of the estimator is\ndemonstrated. A fast algorithm for its calculation is described. The estimator\nis applied to construction of confidence sets for regression parameters in the\nlinear regression with errors in variables. An application to sociological data\nanalysis is considered.","We consider statistical models where functional data are artificially\ncontaminated by independent Wiener processes in order to satisfy privacy\nconstraints. We show that the corrupted observations have a Wiener density\nwhich determines the distribution of the original functional random variables,\nmasked near the origin, uniquely, and we construct a nonparametric estimator of\nthat density. We derive an upper bound for its mean integrated squared error\nwhich has a polynomial convergence rate, and we establish an asymptotic lower\nbound on the minimax convergence rates which is close to the rate attained by\nour estimator. Our estimator requires the choice of a basis and of two\nsmoothing parameters. We propose data-driven ways of choosing them and prove\nthat the asymptotic quality of our estimator is not significantly affected by\nthe empirical parameter selection. We examine the numerical performance of our\nmethod via simulated examples.","Noncollinear magnetic moments in antiferromagnets (AFM) lead to a complex\nbehavior of electrical transport, even to a decreasing resistivity due to an\nincreasing temperature. Proper treatment of such phenomena is required for\nunderstanding AFM systems at finite temperatures; however first-principles\ndescription of these effects is complicated. With ab initio techniques, we\ninvestigate three numerically feasible models of spin fluctuations (magnons)\ninfluencing the transport in AFM CuMnAs. We numerically justified a fully\nrelativistic collinear disordered local moment approach, whose uncompensated\ngeneralization reliably describes spin fluctuations, including anisotropy of\nelectrical transport, in a wide temperature range. A saturation or a decrease\nof resistivity caused by magnons, phonons, and their combination (above approx.\n400 K) was observed and explained by changes in electronic structure. Within\nthe coherent potential approximation, our finite-temperature approaches may be\napplied also to systems with impurities, which are found to have a large impact\nnot only on residual resistivity, but also on canting of magnetic moments from\nthe AFM to the ferromagnetic state.","In this paper, authors focus effort on improving the conventional discrete\nvelocity method (DVM) into a multiscale scheme in finite volume framework for\ngas flow in all flow regimes. Unlike the typical multiscale kinetic methods\nunified gas-kinetic scheme (UGKS) and discrete unified gas-kinetic scheme\n(DUGKS), which concentrate on the evolution of the distribution function at the\ncell interface, in the present scheme the flux for macroscopic variables is\nsplit into the equilibrium part and the nonequilibrium part, and the\nnonequilibrium flux is calculated by integrating the discrete distribution\nfunction at the cell center, which overcomes the excess numerical dissipation\nof the conventional DVM in the continuum flow regime. Afterwards, the\nmacroscopic variables are finally updated by simply integrating the discrete\ndistribution function at the cell center, or by a blend of the increments based\non the macroscopic and the microscopic systems, and the multiscale property is\nachieved. Several test cases, involving unsteady, steady, high speed, low speed\ngas flows in all flow regimes, have been performed, demonstrating the good\nperformance of the multiscale DVM from free molecule to continuum Navier-Stokes\nsolutions and the multiscale property of the scheme is proved.","Over the last years extraordinary advances in experimental and theoretical\ntools have allowed us to monitor and control matter at short time and atomic\nscales with a high-degree of precision. An appealing and challenging route\ntowards engineering materials with tailored properties is to find ways to\ndesign or selectively manipulate materials, especially at the quantum level. To\nthis end, having a state-of-the-art ab initio computer simulation tool that\nenables a reliable and accurate simulation of light-induced changes in the\nphysical and chemical properties of complex systems is of utmost importance.\nThe first principles real-space-based Octopus project was born with that idea\nin mind, providing an unique framework allowing to describe non-equilibrium\nphenomena in molecular complexes, low dimensional materials, and extended\nsystems by accounting for electronic, ionic, and photon quantum mechanical\neffects within a generalized time-dependent density functional theory\nframework. The present article aims to present the new features that have been\nimplemented over the last few years, including technical developments related\nto performance and massive parallelism. We also describe the major theoretical\ndevelopments to address ultrafast light-driven processes, like the new\ntheoretical framework of quantum electrodynamics density-functional formalism\n(QEDFT) for the description of novel light-matter hybrid states. Those\nadvances, and other being released soon as part of the Octopus package, will\nenable the scientific community to simulate and characterize spatial and\ntime-resolved spectroscopies, ultrafast phenomena in molecules and materials,\nand new emergent states of matter (QED-materials).","We introduce QuESTlink, pronounced \"quest link\", an open-source Mathematica\npackage which efficiently emulates quantum computers. By integrating with the\nQuantum Exact Simulation Toolkit (QuEST), QuESTlink offers a high-level,\nexpressive and usable interface to a high-performance, hardware-accelerated\nemulator. Requiring no installation, QuESTlink streamlines the powerful\nanalysis capabilities of Mathematica into the study of quantum systems, even\nutilising remote multicore and GPU hardware. We demonstrate the use of\nQuESTlink to concisely and efficiently simulate several quantum algorithms, and\npresent some comparative benchmarking against core QuEST.","The Shockley-Queisser (SQ) limit provides a convenient metric for predicting\nlight-to-electricity conversion efficiency of a solar cell based on the band\ngap of the light-absorbing layer. In reality, few materials approach this\nradiative limit. We develop a formalism and a computational method to predict\nthe maximum photovoltaic efficiency of imperfect crystals from first\nprinciples. Our scheme includes equilibrium populations of native defects,\ntheir carrier-capture coefficients, and the associated recombination rates.\nWhen applied to kesterite solar cells, we reveal an intrinsic limit of 20% for\nCu2ZnSnSe4, which falls far below the SQ limit of 32%. The effects of atomic\nsubstitution and extrinsic doping are studied, leading to pathways for an\nenhanced efficiency of 31%. This approach can be applied to support\ntargeted-materials selection for future solar-energy technologies.","The multiscale patch scheme is built from given small micro-scale simulations\nof complicated physical processes to empower large macro-scale simulations. By\ncoupling small patches of simulations over unsimulated spatial gaps, large\nsavings in computational time are possible. Here we discuss generalising the\npatch scheme to the case of wave systems on staggered grids in 2D space.\nClassic macro-scale interpolation provides a generic coupling between patches\nthat achieves arbitrarily high order consistency between the emergent\nmacro-scale simulation and the underlying micro-scale dynamics. Eigen-analysis\nindicates that the resultant scheme empowers feasible computation of large\nmacro-scale simulations of wave systems even with complicated underlying\nphysics. As examples we use the scheme to simulate some wave scenarios via a\nturbulent shallow water model.","Computational modeling is widely used to study how individuals and\norganizations search and solve problems in fields such as economics,\nmanagement, cultural evolution, and computer science. We argue that current\ncomputational modelling research on problem-solving needs to address several\nfundamental issues in order to generate more meaningful and falsifiable\ncontributions. Based on comparative simulations and a new type of visualization\nof how to assess the nature of the fitness landscape, we address two key\nassumptions that approaches such as the NK framework rely on: that the NK\ncaptures the continuum of complexity of empirical fitness landscapes, and that\nsearch behavior is a distinct component, independent from the topology of the\nfitness landscape. We show the limitations of the most common approach to\nconceptualize how complex, or rugged, a landscape is, as well as how the nature\nof the fitness landscape is fundamentally intertwined with search behavior.\nFinally, we outline broader implications for how to stimulate problem-solving.","The pathogenesis of adolescent idiopathic scoliosis (AIS) remains poorly\nunderstood and biomechanical data are limited. A deeper insight into spinal\nloading could provide valuable information for the improvement of current\ntreatment strategies. This work therefore aimed at using subject-specific\nmusculoskeletal full-body models of patients with AIS to predict segmental\ncompressive forces around the curve apex and to investigate how these forces\nare affected by simulated load carrying. Models were created based on spatially\ncalibrated biplanar radiographic images from 24 patients with mild to moderate\nAIS and validated by comparing predictions of paravertebral muscle activity\nwith reported values from in vivo studies. Spinal compressive forces were\npredicted during unloaded upright standing as well as upright standing with\nexternal loads of 10%, 15% and 20% of body weight (BW) applied to the scapulae\nto simulate carrying a backpack in the regular way, in front of the body and\nover both shoulders. The validation studies showed higher convex muscle\nactivity, which was comparable to the literature. The implementation of spinal\ndeformity resulted in a 10% increase of compressive force at the curve apex\nduring unloaded upright standing. Apical compressive forces further increased\nby 50-62%, 77-94% and 103-128% for 10%, 15% and 20% BW loads, respectively.\nMoreover, load-dependent compressive force increases were the lowest in the\nregular backpack and the highest in the frontpack and convex conditions. The\npredictions indicated increased segmental compressive forces during unloaded\nstanding, which could be ascribed to the scoliotic deformation. When carrying\nloads, compressive forces further increased depending on the carrying mode and\nthe weight of the load. These results can be used as a basis for further\nstudies investigating segmental loading in AIS patients during functional\nactivities.","A data fusion method for the estimation of residential radon level\ndistribution in any Pennsylvania county is proposed. The method is based on a\nmulti-sample density ratio model with variable tilts and is applied to combined\nradon data from a reference county of interest and its neighboring counties.\nBeaver county and its four immediate neighbors are taken as a case in point.\nThe distribution of radon concentration is estimated in each of six periods,\nand then the analysis is repeated combining the data from all the periods to\nobtain estimates of Beaver threshold probabilities and the corresponding\nconfidence intervals.","The advent of the single cell sequencing era opens new avenues for the\npersonalized treatment. The first but important step is to discover the subject\nheterogeneity at the single cell resolution. In this article, we address the\ntwo-level-clustering problem of simultaneous subject subgroup discovery\n(subject level) and cell type detection (cell level) based on the scRNA-seq\ndata from multiple subjects. However, the current statistical approaches either\ncluster cells without considering the subject heterogeneity or group subjects\nnot using the single-cell information. To overcome the challenges and fill the\ngap between cell clustering and subject grouping, we develop a solid\nnonparametric Bayesian model SCSC (Subject and Cell clustering for Single-Cell\nexpression data) to achieve subject and cell grouping at the same time. SCSC\ndoes not need to prespecify the subject subgroup number or the cell type\nnumber, automatically induces subject subgroup structures and matches cell\ntypes across subjects, and directly models the scRNA-seq raw count data by\ndeliberately considering the data's dropouts, library sizes, and\nover-dispersion. A computationally efficient blocked Gibbs sampler is proposed\nfor the posterior inference. The simulation and the application to a\nmulti-subject iPSC scRNA-seq dataset validate the function of SCSC to discover\nsubject and cell heterogeneity.","It is quite common that the structure of a time series changes abruptly.\nIdentifying these change points and describing the model structure in the\nsegments between these change points is of interest. In this paper, time series\ndata is modelled assuming each segment is an autoregressive time series with\npossibly different autoregressive parameters. This is achieved using two main\nsteps. The first step is to use a likelihood ratio scan based estimation\ntechnique to identify these potential change points to segment the time series.\nOnce these potential change points are identified, modified parametric spectral\ndiscrimination tests are used to validate the proposed segments. A numerical\nstudy is conducted to demonstrate the performance of the proposed method across\nvarious scenarios and compared against other contemporary techniques.","This work considers experimental design in linear models with additive\nerrors. A traditional objective in design is to minimize the variance of the\nestimates of the model parameters. The optimal design, which is found by\nminimizing a convex function of the expected Fisher information, accomplishes\nthis objective, approximately. The inverse of expected Fisher information is\nasymptotically equivalent to the variance of the maximum likelihood estimate.\nIt is often remarked that observed Fisher information is a better measure of\nthe variance of the maximum likelihood estimate than the expected Fisher\ninformation [Efron and Hinkley (1978)]. However, unlike expected Fisher\ninformation, observed Fisher information depends on the observed data and\ncannot be used to design an experiment in advance of data collection. In a\nsequential experiment the observed Fisher information from past observations is\navailable to incorporate into the design of the current observation. In this\nwork an adaptive design that incorporates observed Fisher information is\nproposed. It is shown that this proposed design is optimal, at the limit, with\nrespect to inference and conditional mean square error. In a simulation study\nthe proposed adaptive design performs nearly uniformly better than the optimal\ndesign.","Square lattice designs are often used in trials of new varieties of various\nagricultural crops. However, there are no square lattice designs for 36\nvarieties in blocks of size six for four or more replicates. Here we use three\ndifferent approaches to construct designs for up to eight replicates. All the\ndesigns perform well in terms of giving a low average variance of variety\ncontrasts.\n  Supplementary materials are available online.","Particle physics or High Energy Physics (HEP) studies the elementary\nconstituents of matter and their interactions with each other. Machine Learning\n(ML) has played an important role in HEP analysis and has proven extremely\nsuccessful in this area. Usually, the ML algorithms are trained on numerical\nsimulations of the experimental setup and then applied to the real experimental\ndata. However, any discrepancy between the simulation and real data may lead to\ndramatic consequences concerning the performances of the algorithm on real\ndata. In this paper, we present an application of domain adaptation using a\nDomain Adversarial Neural Network trained on public HEP data. We demonstrate\nthe success of this approach to achieve sim-to-real transfer and ensure the\nconsistency of the ML algorithms performances on real and simulated HEP\ndatasets.","Before any publication, data analysis of high-energy physics experiments must\nbe validated. This validation is granted only if a perfect understanding of the\ndata and the analysis process is demonstrated. Therefore, physicists prefer\nusing transparent machine learning algorithms whose performances highly rely on\nthe suitability of the provided input features. To transform the feature space,\nfeature construction aims at automatically generating new relevant features.\nWhereas most of previous works in this area perform the feature construction\nprior to the model training, we propose here a general framework to embed a\nfeature construction technique adapted to the constraints of high-energy\nphysics in the induction of tree-based models. Experiments on two high-energy\nphysics datasets confirm that a significant gain is obtained on the\nclassification scores, while limiting the number of built features. Since the\nfeatures are built to be interpretable, the whole model is transparent and\nreadable."],["cs.CV","eess.IV","cs.MA","eess.SY","cs.CL","cs.CV","cs.AI","stat.ML","cs.CL","cs.AI","cs.HC","stat.ML","cs.CV","cs.AI","cs.RO","cs.CV","eess.IV","eess.IV","cs.CV","cs.LG","cs.LG","cs.CV","cs.CV","eess.IV","cs.LG","cs.CV","cs.ET","cs.ET","cs.IT","cs.LG","eess.SP","math.NA","stat.ML","q-bio.BM","cs.LG","math.OC","cs.LG","stat.ML","cs.SE","cs.SE","cs.FL","math.ST","math.ST","math.ST","math.ST","cond-mat.mtrl-sci","physics.comp-ph","physics.comp-ph","quant-ph","physics.comp-ph","physics.comp-ph","physics.data-an","physics.med-ph","stat.AP","stat.ME","stat.CO","stat.ME","stat.ME","cs.LG","cs.LG"],["cs.CV, cs.AI, cs.LG","eess.IV, cs.AI, cs.CV, cs.LG","cs.MA, cs.DS","eess.SY, cs.RO, cs.SY","cs.CL, cs.LG","cs.CV, cs.CL, cs.LG","cs.AI, cs.CL, cs.IR","stat.ML, cs.AI, cs.LG","cs.CL, cs.AI, cs.LG","cs.AI, cs.LO, cs.RO","cs.HC, cs.GR","stat.ML, cs.DS, cs.LG","cs.CV, cs.LG, stat.ML","cs.AI, cs.FL, cs.GT, cs.LO","cs.RO, cs.AI, cs.SY, eess.SY","cs.CV","eess.IV, cs.CV","eess.IV, cs.CV, q-bio.QM","cs.CV","cs.LG, cs.CV, stat.ML","cs.LG, cs.CV, physics.comp-ph, stat.ML","cs.CV","cs.CV","eess.IV, cs.CV","cs.LG, cs.CV, stat.ML","cs.CV","cs.ET, cs.LG","cs.ET, physics.app-ph","cs.IT, cs.ET, math.IT","cs.LG, cs.CY, physics.soc-ph, I.2.6; K.4.1","eess.SP, cs.LG, stat.ML","math.NA, cs.LG, cs.NA","stat.ML, cs.LG","q-bio.BM, cs.LG","cs.LG, stat.ML","math.OC, cs.LG","cs.LG, cs.RO, stat.ML","stat.ML, cs.LG, eess.SP, math.ST, stat.TH","cs.SE","cs.SE, cs.LG","cs.FL, cs.SE","math.ST, stat.TH, 62H25","math.ST, stat.ME, stat.TH, 62F10","math.ST, stat.TH","math.ST, stat.TH, 62G07, 62M99, 62H30","cond-mat.mtrl-sci, physics.comp-ph","physics.comp-ph, cs.NA, math.NA, physics.flu-dyn, 76P05, G.1.8; J.2","physics.comp-ph","quant-ph, physics.comp-ph","physics.comp-ph, cond-mat.mtrl-sci","physics.comp-ph, cs.NA, math.DS, math.NA, nlin.PS","physics.data-an, physics.soc-ph","physics.med-ph, physics.bio-ph, q-bio.QM, q-bio.TO","stat.AP, stat.ME","stat.ME, stat.AP","stat.CO, stat.ME","stat.ME","stat.ME, math.CO, 62K10","cs.LG, stat.ML","cs.LG, stat.ML"],[3,4,2,3,2,3,3,3,3,3,2,3,3,4,4,1,2,3,1,3,4,1,1,2,3,1,2,2,3,4,3,3,2,2,2,2,3,5,1,2,2,3,4,2,3,2,6,1,2,2,5,2,4,2,2,2,1,3,2,2],["Computer Vision and Pattern Recognition","Image and Video Processing","Multiagent Systems","eess.SY","Computation and Language","Computer Vision and Pattern Recognition","Artificial Intelligence","Machine Learning","Computation and Language","Artificial Intelligence","Human-Computer Interaction","Machine Learning","Computer Vision and Pattern Recognition","Artificial Intelligence","Robotics","Computer Vision and Pattern Recognition","Image and Video Processing","Image and Video Processing","Computer Vision and Pattern Recognition","Machine Learning","Machine Learning","Computer Vision and Pattern Recognition","Computer Vision and Pattern Recognition","Image and Video Processing","Machine Learning","Computer Vision and Pattern Recognition","Emerging Technologies","Emerging Technologies","Information Theory","Machine Learning","Signal Processing","Numerical Analysis","Machine Learning","Biomolecules","Machine Learning","Optimization and Control","Machine Learning","Machine Learning","Software Engineering","Software Engineering","Formal Languages and Automata Theory","Statistics Theory","Statistics Theory","Statistics Theory","Statistics Theory","Materials Science","Computational Physics","Computational Physics","Quantum Physics","Computational Physics","Computational Physics","Data Analysis, Statistics and Probability","Medical Physics","Applications","Methodology","Computation","Methodology","Methodology","Machine Learning","Machine Learning"],["Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning","Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning","Multiagent Systems, Data Structures and Algorithms","Robotics, Systems and Control","Computation and Language, Machine Learning","Computer Vision and Pattern Recognition, Computation and Language, Machine Learning","Artificial Intelligence, Computation and Language, Information Retrieval","Machine Learning, Artificial Intelligence, Machine Learning","Computation and Language, Artificial Intelligence, Machine Learning","Artificial Intelligence, Logic in Computer Science, Robotics","Human-Computer Interaction, Graphics","Machine Learning, Data Structures and Algorithms, Machine Learning","Computer Vision and Pattern Recognition, Machine Learning, Machine Learning","Artificial Intelligence, Formal Languages and Automata Theory, Computer Science and Game Theory, Logic in Computer Science","Robotics, Artificial Intelligence, Systems and Control","Computer Vision and Pattern Recognition","Image and Video Processing, Computer Vision and Pattern Recognition","Image and Video Processing, Computer Vision and Pattern Recognition, Quantitative Methods","Computer Vision and Pattern Recognition","Machine Learning, Computer Vision and Pattern Recognition, Machine Learning","Machine Learning, Computer Vision and Pattern Recognition, Computational Physics, Machine Learning","Computer Vision and Pattern Recognition","Computer Vision and Pattern Recognition","Image and Video Processing, Computer Vision and Pattern Recognition","Machine Learning, Computer Vision and Pattern Recognition, Machine Learning","Computer Vision and Pattern Recognition","Emerging Technologies, Machine Learning","Emerging Technologies, Applied Physics","Information Theory, Emerging Technologies, Information Theory","Machine Learning, Computers and Society, Physics and Society","Signal Processing, Machine Learning, Machine Learning","Numerical Analysis, Machine Learning, Numerical Analysis","Machine Learning, Machine Learning","Biomolecules, Machine Learning","Machine Learning, Machine Learning","Optimization and Control, Machine Learning","Machine Learning, Robotics, Machine Learning","Machine Learning, Machine Learning, Signal Processing, Statistics Theory, Statistics Theory","Software Engineering","Software Engineering, Machine Learning","Formal Languages and Automata Theory, Software Engineering","Statistics Theory, Statistics Theory","Statistics Theory, Methodology, Statistics Theory","Statistics Theory, Statistics Theory","Statistics Theory, Statistics Theory","Materials Science, Computational Physics","Computational Physics, Numerical Analysis, Numerical Analysis, Fluid Dynamics","Computational Physics","Quantum Physics, Computational Physics","Computational Physics, Materials Science","Computational Physics, Numerical Analysis, Dynamical Systems, Numerical Analysis, Pattern Formation and Solitons","Data Analysis, Statistics and Probability, Physics and Society","Medical Physics, Biological Physics, Quantitative Methods, Tissues and Organs","Applications, Methodology","Methodology, Applications","Computation, Methodology","Methodology","Methodology, Combinatorics","Machine Learning, Machine Learning","Machine Learning, Machine Learning"],["Ali Farhadi","Ben Glocker","Boi Faltings","Zhao-Xu Yang","Ruyang Xu","Shahid Khattak","Qingpeng Zhang","Micol Marchetti-Bowick","Dan Roth","Takao Moriyama","Wolfgang Stuerzlinger","Shlomo Zilberstein","L. Wang","Moshe Vardi","Hussein Abbass","Ross Girshick","Matthew J. Hoffman","Matteo Rucco","Matthew Walmer","Qi Zhao","Brian K. Spears","Shaofan Wang","Peter Kontschieder","Xiaocuan Li","Piyush Rai","Gui-Song Xia","Miao Hu","Sumeet Gupta","Ying-Chang Liang","Luis F. Lafuerza","Mojtaba Soltanalian","Karen Willcox","Julien Mairal","Martin KM Engqvist","Yashaswi Verma","Sriram Sankaranarayanan","Jean-Sebastien Valois","Cristian R. Rojas","Maciej Boniecki","Alexander Egyed","Geguang Pu","J. Palarea-Albaladejo","E. Velayati Moghaddam 1","Olena Sugakova","Alexander Meister","Ilja Turek","Chengwen Zhong","Angel Rubio","Simon C Benjamin","Aron Walsh","A. J. Roberts","Jacob F. Sherson","Dennis E. Anderson","Benjamin Kedem","Xiangyu Luo","Georgy Sofronov","Adam Lane","E. R. Williams","Noëlie Cherrier","Franck Sabatié"],["Luca Weihs, Aniruddha Kembhavi, Winson Han, Alvaro Herrasti, Eric Kolve, Dustin Schwenk, Roozbeh Mottaghi, Ali Farhadi","Daniel C. Castro, Ian Walker, Ben Glocker","Panayiotis Danassis, Marija Sakota, Aris Filos-Ratsikas, Boi Faltings","Xiaowei Gu, Muhammad Aurangzeb Khan, Plamen Angelov, Bikash Tiwary, Elnaz Shafipour Yourdshah, Zhao-Xu Yang","Heng Yang, Biqing Zeng, JianHao Yang, Youwei Song, Ruyang Xu","Hazrat Ali, Ahsan Ullah, Talha Iqbal, Shahid Khattak","Fengshi Jing, Qingpeng Zhang","Donsuk Lee, Yiming Gu, Jerrick Hoang, Micol Marchetti-Bowick","Karthikeyan K, Zihan Wang, Stephen Mayhew, Dan Roth","Michiaki Tatsubori, Asim Munawar, Takao Moriyama","Yue Jiang, Ruofei Du, Christof Lutteroth, Wolfgang Stuerzlinger","Sandhya Saisubramanian, Sainyam Galhotra, Shlomo Zilberstein","JT Wu, L. Wang","Shufang Zhu, Giuseppe De Giacomo, Geguang Pu, Moshe Vardi","Nathan K Long, Karl Sammut, Daniel Sgarioto, Matthew Garratt, Hussein Abbass","Alexander Kirillov, Yuxin Wu, Kaiming He, Ross Girshick","Aneesh Rangnekar, Nilay Mokashi, Emmett Ientilucci, Christopher Kanan, Matthew J. Hoffman","Matteo Rucco","Anneliese Braunegg, Amartya Chakraborty, Michael Krumdick, Nicole Lape, Sara Leary, Keith Manville, Elizabeth Merkhofer, Laura Strickhart, Matthew Walmer","Yan Luo, Yongkang Wong, Mohan S. Kankanhalli, Qi Zhao","Rushil Anirudh, Jayaraman J. Thiagarajan, Peer-Timo Bremer, Brian K. Spears","Tian Liu, Lichun Wang, Shaofan Wang","Andrea Simonelli, Samuel Rota Bulò, Lorenzo Porzi, Elisa Ricci, Peter Kontschieder","Tangxin Xie, Xin Yang, Yu Jia, Chen Zu, Xiaocuan Li","Yatin Dandi, Aniket Das, Soumye Singhal, Vinay P. Namboodiri, Piyush Rai","Zi-Ming Wang, Meng-Han Li, Gui-Song Xia","Fan Zhang, Miao Hu","Sandeep Thirumala, Yi-Tse Hung, Shubham Jain, Arnab Raha, Niharika Thakuria, Vijay Raghunathan, Anand Raghunathan, Zhihong Chen, Sumeet Gupta","Shimin Gong, Xiao Lu, Dinh Thai Hoang, Dusit Niyato, Lei Shu, Dong In Kim, Ying-Chang Liang","Przemyslaw A. Grabowicz, Kenta Takatsu, Luis F. Lafuerza","Shahin Khobahi, Arindam Bose, Mojtaba Soltanalian","Elizabeth Qian, Boris Kramer, Benjamin Peherstorfer, Karen Willcox","Julien Mairal","Gang Li, Jan Zrimec, Boyang Ji, Jun Geng, Johan Larsbrink, Aleksej Zelezniak, Jens Nielsen, Martin KM Engqvist","Yashaswi Verma","Yoshua Bengio, Emma Frejinger, Andrea Lodi, Rahul Patel, Sriram Sankaranarayanan","Geunseob, Oh, Jean-Sebastien Valois","Rodrigo A. González, Cristian R. Rojas","Zenon Gniazdowski, Maciej Boniecki","Hannes Thaller, Lukas Linsbauer, Rudolf Ramler, Alexander Egyed","Yihao Huang, Jincao Feng, Hanyue Zheng, Jiayi Zhu, Shang Wang, Siyuan Jiang, Weikai Miao, Geguang Pu","R. Talska, A. Menafoglio, K. Hron, J. J. Egozcue, J. Palarea-Albaladejo","M. Doostparast, M. Hashempour, E. Velayati Moghaddam 1","Rostyslav Maiboroda, Olena Sugakova","Aurore Delaigle, Alexander Meister","David Wagenknecht, Karel Výborný, Karel Carva, Ilja Turek","Ruifeng Yuan, Sha Liu, Chengwen Zhong","Nicolas Tancogne-Dejean, Micael J. T. Oliveira, Xavier Andrade, Heiko Appel, Carlos H. Borca, Guillaume Le Breton, Florian Buchholz, Alberto Castro, Stefano Corni, Alfredo A. Correa, Umberto De Giovannini, Alain Delgado, Florian G. Eich, Johannes Flick, Gabriel Gil, Adrián Gomez, Nicole Helbig, Hannes Hübener, René Jestädt, Joaquim Jornet-Somoza, Ask H. Larsen, Irina V. Lebedeva, Martin Lüders, Miguel A. L. Marques, Sebastian T. Ohlmann, Silvio Pipolo, Markus Rampp, Carlo A. Rozzi, David A. Strubbe, Shunsuke A. Sato, Christian Schäfer, Iris Theophilou, Alicia Welden, Angel Rubio","Tyson Jones, Simon C Benjamin","Sunghyun Kim, José A. Márquez, 2 Thomas Unold, Aron Walsh","J. E. Bunder, J. Divahar, Ioannis G. Kevrekidis, Trent W. Mattner, A. J. Roberts","Oana Vuculescu, Mads Kock Pedersen, Carsten Bergenholtz, Jacob F. Sherson","Stefan Schmid, Katelyn A. Burkhart, Brett T. Allaire, Daniel Grindle, Tito Bassani, Fabio Galbusera, Dennis E. Anderson","Xuze Zhang, Saumyadipta Pyne, Benjamin Kedem","Qiuyu Wu, Xiangyu Luo","Lijing Ma, Andrew Grant, Georgy Sofronov","Adam Lane","R. A. Bailey, Peter J. Cameron, L. H. Soicher, E. R. Williams","Marouen Baalouch, Maxime Defurne, Jean-Philippe Poli, Noëlie Cherrier","Noëlie Cherrier, Maxime Defurne, Jean-Philippe Poli, Franck Sabatié"],[8,3,4,6,5,4,2,4,4,3,4,3,2,4,5,4,5,1,9,4,4,3,5,5,5,3,2,9,7,3,3,4,1,8,1,5,3,2,2,4,8,5,3,2,2,4,3,34,2,4,5,4,7,3,2,3,1,4,4,4],["http://arxiv.org/pdf/1912.08195v1","http://arxiv.org/pdf/1912.08142v1","http://arxiv.org/pdf/1912.08066v1","http://arxiv.org/pdf/1912.08057v1","http://arxiv.org/pdf/1912.07976v1","http://arxiv.org/pdf/1912.07943v1","http://arxiv.org/pdf/1912.07915v1","http://arxiv.org/pdf/1912.07882v1","http://arxiv.org/pdf/1912.07840v1","http://arxiv.org/pdf/1912.07834v1","http://arxiv.org/pdf/1912.07827v1","http://arxiv.org/pdf/1912.07820v1","http://arxiv.org/pdf/1912.07819v1","http://arxiv.org/pdf/1912.07804v1","http://arxiv.org/pdf/1912.07796v1","http://arxiv.org/pdf/1912.08193v1","http://arxiv.org/pdf/1912.08178v1","http://arxiv.org/pdf/1912.08167v1","http://arxiv.org/pdf/1912.08166v1","http://arxiv.org/pdf/1912.08136v1","http://arxiv.org/pdf/1912.08113v1","http://arxiv.org/pdf/1912.08059v1","http://arxiv.org/pdf/1912.08035v1","http://arxiv.org/pdf/1912.08002v1","http://arxiv.org/pdf/1912.07991v1","http://arxiv.org/pdf/1912.07971v1","http://arxiv.org/pdf/1912.07829v1","http://arxiv.org/pdf/1912.07821v1","http://arxiv.org/pdf/1912.07794v1","http://arxiv.org/pdf/1912.08189v1","http://arxiv.org/pdf/1912.08180v1","http://arxiv.org/pdf/1912.08177v1","http://arxiv.org/pdf/1912.08165v1","http://arxiv.org/pdf/1912.08141v1","http://arxiv.org/pdf/1912.08140v1","http://arxiv.org/pdf/1912.08112v1","http://arxiv.org/pdf/1912.08111v1","http://arxiv.org/pdf/1912.08103v1","http://arxiv.org/pdf/1912.08138v1","http://arxiv.org/pdf/1912.07936v1","http://arxiv.org/pdf/1912.07817v1","http://arxiv.org/pdf/1912.08003v1","http://arxiv.org/pdf/1912.07967v1","http://arxiv.org/pdf/1912.07948v1","http://arxiv.org/pdf/1912.07879v1","http://arxiv.org/pdf/1912.08025v1","http://arxiv.org/pdf/1912.07982v1","http://arxiv.org/pdf/1912.07921v1","http://arxiv.org/pdf/1912.07904v1","http://arxiv.org/pdf/1912.07889v1","http://arxiv.org/pdf/1912.07815v1","http://arxiv.org/pdf/1912.07954v1","http://arxiv.org/pdf/1912.07893v1","http://arxiv.org/pdf/1912.08149v1","http://arxiv.org/pdf/1912.08050v1","http://arxiv.org/pdf/1912.07775v1","http://arxiv.org/pdf/1912.08162v1","http://arxiv.org/pdf/1912.08087v1","http://arxiv.org/pdf/1912.08001v1","http://arxiv.org/pdf/1912.07999v1"],["http://arxiv.org/abs/1912.08195v1","http://arxiv.org/abs/1912.08142v1","http://arxiv.org/abs/1912.08066v1","http://arxiv.org/abs/1912.08057v1","http://arxiv.org/abs/1912.07976v1","http://arxiv.org/abs/1912.07943v1","http://arxiv.org/abs/1912.07915v1","http://arxiv.org/abs/1912.07882v1","http://arxiv.org/abs/1912.07840v1","http://arxiv.org/abs/1912.07834v1","http://arxiv.org/abs/1912.07827v1","http://arxiv.org/abs/1912.07820v1","http://arxiv.org/abs/1912.07819v1","http://arxiv.org/abs/1912.07804v1","http://arxiv.org/abs/1912.07796v1","http://arxiv.org/abs/1912.08193v1","http://arxiv.org/abs/1912.08178v1","http://arxiv.org/abs/1912.08167v1","http://arxiv.org/abs/1912.08166v1","http://arxiv.org/abs/1912.08136v1","http://arxiv.org/abs/1912.08113v1","http://arxiv.org/abs/1912.08059v1","http://arxiv.org/abs/1912.08035v1","http://arxiv.org/abs/1912.08002v1","http://arxiv.org/abs/1912.07991v1","http://arxiv.org/abs/1912.07971v1","http://arxiv.org/abs/1912.07829v1","http://arxiv.org/abs/1912.07821v1","http://arxiv.org/abs/1912.07794v1","http://arxiv.org/abs/1912.08189v1","http://arxiv.org/abs/1912.08180v1","http://arxiv.org/abs/1912.08177v1","http://arxiv.org/abs/1912.08165v1","http://arxiv.org/abs/1912.08141v1","http://arxiv.org/abs/1912.08140v1","http://arxiv.org/abs/1912.08112v1","http://arxiv.org/abs/1912.08111v1","http://arxiv.org/abs/1912.08103v1","http://arxiv.org/abs/1912.08138v1","http://arxiv.org/abs/1912.07936v1","http://arxiv.org/abs/1912.07817v1","http://arxiv.org/abs/1912.08003v1","http://arxiv.org/abs/1912.07967v1","http://arxiv.org/abs/1912.07948v1","http://arxiv.org/abs/1912.07879v1","http://arxiv.org/abs/1912.08025v1","http://arxiv.org/abs/1912.07982v1","http://arxiv.org/abs/1912.07921v1","http://arxiv.org/abs/1912.07904v1","http://arxiv.org/abs/1912.07889v1","http://arxiv.org/abs/1912.07815v1","http://arxiv.org/abs/1912.07954v1","http://arxiv.org/abs/1912.07893v1","http://arxiv.org/abs/1912.08149v1","http://arxiv.org/abs/1912.08050v1","http://arxiv.org/abs/1912.07775v1","http://arxiv.org/abs/1912.08162v1","http://arxiv.org/abs/1912.08087v1","http://arxiv.org/abs/1912.08001v1","http://arxiv.org/abs/1912.07999v1"],["2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17","2019-12-17"]],"container":"<table class=\"compact\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>summary<\/th>\n      <th>primary_tag<\/th>\n      <th>tags<\/th>\n      <th>n_tags<\/th>\n      <th>primary_category<\/th>\n      <th>categories<\/th>\n      <th>author<\/th>\n      <th>authors<\/th>\n      <th>n_authors<\/th>\n      <th>url_pdf<\/th>\n      <th>url_href<\/th>\n      <th>date<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[5,10]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
