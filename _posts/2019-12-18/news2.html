<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Daily arXiv Articles in the areas of Data Science</title>
  
  <meta property="description" itemprop="description" content="There are 60 articles published today."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-12-18"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-12-18"/>
  <meta name="article:author" content="Bryan Whiting"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Daily arXiv Articles in the areas of Data Science"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="There are 60 articles published today."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Daily arXiv Articles in the areas of Data Science"/>
  <meta property="twitter:description" content="There are 60 articles published today."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Daily arXiv Articles in the areas of Data Science"]},{"type":"character","attributes":{},"value":["There are 60 articles published today.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Bryan Whiting"]},{"type":"character","attributes":{},"value":["https://www.bryanwhiting.com"]}]}]},{"type":"character","attributes":{},"value":["2019-12-18"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["arxiv.csv","news_files/bowser-1.9.3/bowser.min.js","news_files/crosstalk-1.0.0/css/crosstalk.css","news_files/crosstalk-1.0.0/js/crosstalk.js","news_files/crosstalk-1.0.0/js/crosstalk.js.map","news_files/crosstalk-1.0.0/js/crosstalk.min.js","news_files/crosstalk-1.0.0/js/crosstalk.min.js.map","news_files/datatables-binding-0.4/css/datatables-crosstalk.css","news_files/datatables-binding-0.4/datatables.js","news_files/datatables-binding-0.4/datatables.yaml","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/css/autoFill.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/autoFill.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/AutoFill/js/dataTables.autoFill.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/css/buttons.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.colVis.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.flash.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.html5.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.print.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/buttons.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/dataTables.buttons.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/jszip.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/pdfmake.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/js/vfs_fonts.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Buttons/swf/flashExport.swf","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/css/colReorder.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/ColReorder/js/dataTables.colReorder.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/css/fixedColumns.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedColumns/js/dataTables.fixedColumns.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/css/fixedHeader.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/FixedHeader/js/dataTables.fixedHeader.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/css/keyTable.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/KeyTable/js/dataTables.keyTable.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/css/responsive.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/dataTables.responsive.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Responsive/js/responsive.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/css/rowGroup.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowGroup/js/dataTables.rowGroup.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/css/rowReorder.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/RowReorder/js/dataTables.rowReorder.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/css/scroller.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Scroller/js/dataTables.scroller.min.js","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/css/select.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables-extensions/Select/js/dataTables.select.min.js","news_files/datatables-binding-0.4/lib/datatables-plugins/natural/natural.js","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/dataTables.searchHighlight.css","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/dataTables.searchHighlight.min.js","news_files/datatables-binding-0.4/lib/datatables-plugins/searchHighlight/jquery.highlight.js","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap.extra.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.bootstrap4.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.foundation.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.jqueryui.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.material.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.semanticui.min.css","news_files/datatables-binding-0.4/lib/datatables/css/dataTables.uikit.min.css","news_files/datatables-binding-0.4/lib/datatables/css/jquery.dataTables.extra.css","news_files/datatables-binding-0.4/lib/datatables/css/jquery.dataTables.min.css","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.bootstrap.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.bootstrap4.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.foundation.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.jqueryui.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.material.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.semanticui.min.js","news_files/datatables-binding-0.4/lib/datatables/js/dataTables.uikit.min.js","news_files/datatables-binding-0.4/lib/datatables/js/jquery.dataTables.min.js","news_files/datatables-binding-0.4/lib/datatables/license.txt","news_files/datatables-binding-0.4/lib/jquery/jquery.min.js","news_files/datatables-binding-0.4/lib/jquery/LICENSE.txt","news_files/datatables-binding-0.4/lib/nouislider/jquery.nouislider.min.css","news_files/datatables-binding-0.4/lib/nouislider/jquery.nouislider.min.js","news_files/datatables-binding-0.4/lib/selectize/selectize.bootstrap3.css","news_files/datatables-binding-0.4/lib/selectize/selectize.min.js","news_files/datatables-css-0.0.0/datatables-crosstalk.css","news_files/distill-2.2.21/template.v2.js","news_files/dt-core-1.10.16/css/jquery.dataTables.extra.css","news_files/dt-core-1.10.16/css/jquery.dataTables.min.css","news_files/dt-core-1.10.16/js/jquery.dataTables.min.js","news_files/htmlwidgets-1.2/htmlwidgets.js","news_files/jquery-1.11.3/jquery.min.js","news_files/jquery-1.12.4/jquery.min.js","news_files/jquery-1.12.4/LICENSE.txt","news_files/webcomponents-2.0.0/webcomponents.js","news.html","news2_files/bowser-1.9.3/bowser.min.js","news2_files/distill-2.2.21/template.v2.js","news2_files/jquery-1.11.3/jquery.min.js","news2_files/kePrint-0.0.1/kePrint.js","news2_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="news2_files/kePrint-0.0.1/kePrint.js"></script>
  <script src="news2_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="news2_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="news2_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="news2_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Daily arXiv Articles in the areas of Data Science","description":"There are 60 articles published today.","authors":[{"author":"Bryan Whiting","authorURL":"https://www.bryanwhiting.com","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-12-18T00:00:00.000-05:00","citationText":"Whiting, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Daily arXiv Articles in the areas of Data Science</h1>
<p>There are 60 articles published today.</p>
</div>

<div class="d-byline">
  Bryan Whiting <a href="https://www.bryanwhiting.com" class="uri">https://www.bryanwhiting.com</a> 
  
<br/>2019-12-18
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#breakdown-of-arxiv-publication-counts">Breakdown of arXiv Publication Counts</a></li>
<li><a href="#articles-for-statitstics-machine-learning-econonmetrics-and-finance">Articles for Statitstics, Machine Learning Econonmetrics, and Finance</a><ul>
<li><a href="#applications--stat-ap-">Applications (stat.AP)</a></li>
<li><a href="#machine-learning--stat-ml-">Machine Learning (stat.ML)</a></li>
<li><a href="#machine-learning--cs-lg-">Machine Learning (cs.LG)</a></li>
</ul></li>
<li><a href="#data-science-arxiv-by-primary-tag">Data Science arXiv by Primary Tag</a><ul>
<li><a href="#computer-science">Computer Science</a></li>
<li><a href="#statistics">Statistics</a></li>
<li><a href="#elec.-eng.-and-systems-science">Elec. Eng. and Systems Science</a></li>
<li><a href="#mathematics">Mathematics</a></li>
<li><a href="#physics">Physics</a></li>
<li><a href="#condensed-matter">Condensed Matter</a></li>
<li><a href="#quantitative-biology">Quantitative Biology</a></li>
<li><a href="#quantum-physics">Quantum Physics</a></li>
</ul></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="breakdown-of-arxiv-publication-counts">Breakdown of arXiv Publication Counts</h2>
<p>Yesterday’s counts of submitted papers on www.arxiv.org grouped by primary subject. Click the links in the table to be re-directed to the abstracts below. The links under <code>Subject</code> will redirect you to abstracts with the primary subject (there can only be one primary subject on arXiv). The links under <code>Category</code> will redirect you to all publications yesterday with a given tag (primary or secondary).</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-1">Table 1: </span>Number of articles by subject and primary category. Colored titles represent hyperlinks that take you below to abstracts. Key - Subject: Computer Science (5) means there were 5 articles with primary tag CS. Category: Machine Learning (cs.LG) N = 8 (16) means there were 8 primary articles with the (cs.LG) tag but 16 articles had it as a secondary tag, so there should be 24 in total. Click this link to be taken to all 24. Only select categories are highlighted because they are of particular interest to applied data scientists.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Subject
</th>
<th style="text-align:left;">
Category
</th>
<th style="text-align:left;">
N
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;vertical-align: top !important;" rowspan="11">
<a href="#computer-science" style=" font-weight: bold;    color: #d9230f !important;">Computer Science (30)</a>
</td>
<td style="text-align:left;">
<a href="#machine-learning--cs-lg-" style=" font-weight: bold;    color: #d9230f !important;">Machine Learning (cs.LG)</a>
</td>
<td style="text-align:left;">
8 (16)
</td>
</tr>
<tr>
<td style="text-align:left;">
Computer Vision and Pattern Recognition (cs.CV)
</td>
<td style="text-align:left;">
8 (7)
</td>
</tr>
<tr>
<td style="text-align:left;">
Artificial Intelligence (cs.AI)
</td>
<td style="text-align:left;">
3 (5)
</td>
</tr>
<tr>
<td style="text-align:left;">
Computation and Language (cs.CL)
</td>
<td style="text-align:left;">
2 (2)
</td>
</tr>
<tr>
<td style="text-align:left;">
Emerging Technologies (cs.ET)
</td>
<td style="text-align:left;">
2 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Software Engineering (cs.SE)
</td>
<td style="text-align:left;">
2 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Robotics (cs.RO)
</td>
<td style="text-align:left;">
1 (3)
</td>
</tr>
<tr>
<td style="text-align:left;">
Formal Languages and Automata Theory (cs.FL)
</td>
<td style="text-align:left;">
1 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Human-Computer Interaction (cs.HC)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Information Theory (cs.IT)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiagent Systems (cs.MA)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;vertical-align: top !important;" rowspan="4">
<a href="#statistics" style=" font-weight: bold;    color: #d9230f !important;">Statistics (9)</a>
</td>
<td style="text-align:left;">
<a href="#machine-learning--stat-ml-" style=" font-weight: bold;    color: #d9230f !important;">Machine Learning (stat.ML)</a>
</td>
<td style="text-align:left;">
4 (9)
</td>
</tr>
<tr>
<td style="text-align:left;">
Methodology (stat.ME)
</td>
<td style="text-align:left;">
3 (3)
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="#applications--stat-ap-" style=" font-weight: bold;    color: #d9230f !important;">Applications (stat.AP)</a>
</td>
<td style="text-align:left;">
1 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Computation (stat.CO)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;vertical-align: top !important;" rowspan="3">
<a href="#elec.-eng.%20and%20systems%20science" style=" font-weight: bold;    color: #d9230f !important;">Elec. Eng. and Systems Science (6)</a>
</td>
<td style="text-align:left;">
Image and Video Processing (eess.IV)
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
eess.SY (eess.SY)
</td>
<td style="text-align:left;">
1 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Signal Processing (eess.SP)
</td>
<td style="text-align:left;">
1 (1)
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;vertical-align: top !important;" rowspan="3">
<a href="#mathematics" style=" font-weight: bold;    color: #d9230f !important;">Mathematics (6)</a>
</td>
<td style="text-align:left;">
Statistics Theory (math.ST)
</td>
<td style="text-align:left;">
4 (1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Numerical Analysis (math.NA)
</td>
<td style="text-align:left;">
1 (2)
</td>
</tr>
<tr>
<td style="text-align:left;">
Optimization and Control (math.OC)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;vertical-align: top !important;" rowspan="3">
<a href="#physics" style=" font-weight: bold;    color: #d9230f !important;">Physics (6)</a>
</td>
<td style="text-align:left;">
Computational Physics (physics.comp-ph)
</td>
<td style="text-align:left;">
4 (3)
</td>
</tr>
<tr>
<td style="text-align:left;">
Data Analysis, Statistics and Probability (physics.data-an)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Medical Physics (physics.med-ph)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
<a href="#condensed-matter" style=" font-weight: bold;    color: #d9230f !important;">Condensed Matter (1)</a>
</td>
<td style="text-align:left;">
Materials Science (cond-mat.mtrl-sci)
</td>
<td style="text-align:left;">
1 (1)
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
<a href="#quantitative-biology" style=" font-weight: bold;    color: #d9230f !important;">Quantitative Biology (1)</a>
</td>
<td style="text-align:left;">
Biomolecules (q-bio.BM)
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
<a href="#quantum-physics" style=" font-weight: bold;    color: #d9230f !important;">Quantum Physics (1)</a>
</td>
<td style="text-align:left;">
Quantum Physics (quant-ph)
</td>
<td style="text-align:left;">
1
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="articles-for-statitstics-machine-learning-econonmetrics-and-finance">Articles for Statitstics, Machine Learning Econonmetrics, and Finance</h2>
<p>This section contains all articles with any tag of <code>stat.AP</code>, <code>stat.co</code>, <code>stat.ML</code>, <code>cs.LG</code>, <code>q-fin.ST</code>, <code>q-fin.EC</code>, or <code>econ-EM</code>.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-screen-inset">

<h3 id="applications--stat-ap-">Applications (stat.AP)</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="2">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Applications (stat.AP)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08149v1" style="color: #d9230f">Estimation of Residential Radon Concentration in Pennsylvania Counties by Data Fusion</a></b><br><em>Applications, Methodology</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08149v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A data fusion method for the estimation of residential radon level distribution in any Pennsylvania county is proposed. The method is based on a multi-sample density ratio model with variable tilts and is applied to combined radon data from a reference county of interest and its neighboring counties. …</summary><br> Beaver county and its four immediate neighbors are taken as a case in point. The distribution of radon concentration is estimated in each of six periods, and then the analysis is repeated combining the data from all the periods to obtain estimates of Beaver threshold probabilities and the corresponding confidence intervals.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08050v1" style="color: #d9230f">A nonparametric Bayesian approach to simultaneous subject and cell heterogeneity discovery for single cell RNA-seq data</a></b><br><em>Methodology, Applications</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08050v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The advent of the single cell sequencing era opens new avenues for the personalized treatment. The first but important step is to discover the subject heterogeneity at the single cell resolution. …</summary><br> In this article, we address the two-level-clustering problem of simultaneous subject subgroup discovery (subject level) and cell type detection (cell level) based on the scRNA-seq data from multiple subjects. However, the current statistical approaches either cluster cells without considering the subject heterogeneity or group subjects not using the single-cell information. To overcome the challenges and fill the gap between cell clustering and subject grouping, we develop a solid nonparametric Bayesian model SCSC (Subject and Cell clustering for Single-Cell expression data) to achieve subject and cell grouping at the same time. SCSC does not need to prespecify the subject subgroup number or the cell type number, automatically induces subject subgroup structures and matches cell types across subjects, and directly models the scRNA-seq raw count data by deliberately considering the data’s dropouts, library sizes, and over-dispersion. A computationally efficient blocked Gibbs sampler is proposed for the posterior inference. The simulation and the application to a multi-subject iPSC scRNA-seq dataset validate the function of SCSC to discover subject and cell heterogeneity.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="machine-learning--stat-ml-">Machine Learning (stat.ML)</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="13">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Machine Learning (stat.ML)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07991v1" style="color: #d9230f">Jointly Trained Image and Video Generation using Residual Vectors</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07991v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. …</summary><br> We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach’s compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique’s capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07882v1" style="color: #d9230f">Joint Interaction and Trajectory Prediction for Autonomous Driving using Graph Neural Networks</a></b><br><em>Machine Learning, Artificial Intelligence, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07882v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we aim to predict the future motion of vehicles in a traffic scene by explicitly modeling their pairwise interactions. Specifically, we propose a graph neural network that jointly predicts the discrete interaction modes and 5-second future trajectories for all agents in the scene. …</summary><br> Our model infers an interaction graph whose nodes are agents and whose edges capture the long-term interaction intents among the agents. In order to train the model to recognize known modes of interaction, we introduce an auto-labeling function to generate ground truth interaction labels. Using a large-scale real-world driving dataset, we demonstrate that jointly predicting the trajectories along with the explicit interaction types leads to significantly lower trajectory error than baseline methods. Finally, we show through simulation studies that the learned interaction modes are semantically meaningful.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08136v1" style="color: #d9230f">Direction Concentration Learning: Enhancing Congruency in Machine Learning</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08136v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>One of the well-known challenges in computer vision tasks is the visual diversity of images, which could result in an agreement or disagreement between the learned knowledge and the visual content exhibited by the current observation. In this work, we first define such an agreement in a concepts learning process as congruency. …</summary><br> Formally, given a particular task and sufficiently large dataset, the congruency issue occurs in the learning process whereby the task-specific semantics in the training data are highly varying. We propose a Direction Concentration Learning (DCL) method to improve congruency in the learning process, where enhancing congruency influences the convergence path to be less circuitous. The experimental results show that the proposed DCL method generalizes to state-of-the-art models and optimizers, as well as improves the performances of saliency prediction task, continual learning task, and classification task. Moreover, it helps mitigate the catastrophic forgetting problem in the continual learning task. The code is publicly available at <a href="https://github.com/luoyan407/congruency" class="uri">https://github.com/luoyan407/congruency</a>.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08113v1" style="color: #d9230f">Improved Surrogates in Inertial Confinement Fusion with Manifold and Cycle Consistencies</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Computational Physics, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08113v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Neural networks have become very popular in surrogate modeling because of their ability to characterize arbitrary, high dimensional functions in a data driven fashion. This paper advocates for the training of surrogates that are consistent with the physical manifold – i. …</summary><br>e., predictions are always physically meaningful, and are cyclically consistent – i.e., when the predictions of the surrogate, when passed through an independently trained inverse model give back the original input parameters. We find that these two consistencies lead to surrogates that are superior in terms of predictive performance, more resilient to sampling artifacts, and tend to be more data efficient. Using Inertial Confinement Fusion (ICF) as a test bed problem, we model a 1D semi-analytic numerical simulator and demonstrate the effectiveness of our approach. Code and data are available at <a href="https://github.com/rushilanirudh/macc/" class="uri">https://github.com/rushilanirudh/macc/</a>
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08001v1" style="color: #d9230f">Sim-to-Real Domain Adaptation For High Energy Physics</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08001v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Particle physics or High Energy Physics (HEP) studies the elementary constituents of matter and their interactions with each other. Machine Learning (ML) has played an important role in HEP analysis and has proven extremely successful in this area. …</summary><br> Usually, the ML algorithms are trained on numerical simulations of the experimental setup and then applied to the real experimental data. However, any discrepancy between the simulation and real data may lead to dramatic consequences concerning the performances of the algorithm on real data. In this paper, we present an application of domain adaptation using a Domain Adversarial Neural Network trained on public HEP data. We demonstrate the success of this approach to achieve sim-to-real transfer and ensure the consistency of the ML algorithms performances on real and simulated HEP datasets.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07999v1" style="color: #d9230f">Embedded Constrained Feature Construction for High-Energy Physics Data Classification</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07999v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Before any publication, data analysis of high-energy physics experiments must be validated. This validation is granted only if a perfect understanding of the data and the analysis process is demonstrated. …</summary><br> Therefore, physicists prefer using transparent machine learning algorithms whose performances highly rely on the suitability of the provided input features. To transform the feature space, feature construction aims at automatically generating new relevant features. Whereas most of previous works in this area perform the feature construction prior to the model training, we propose here a general framework to embed a feature construction technique adapted to the constraints of high-energy physics in the induction of tree-based models. Experiments on two high-energy physics datasets confirm that a significant gain is obtained on the classification scores, while limiting the number of built features. Since the features are built to be interpretable, the whole model is transparent and readable.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07820v1" style="color: #d9230f">Balancing the Tradeoff Between Clustering Value and Interpretability</a></b><br><em>Machine Learning, Data Structures and Algorithms, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07820v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Graph clustering groups entities – the vertices of a graph – based on their similarity, typically using a complex distance function over a large number of features. Successful integration of clustering approaches in automated decision-support systems hinges on the interpretability of the resulting clusters. …</summary><br> This paper addresses the problem of generating interpretable clusters, given features of interest that signify interpretability to an end-user, by optimizing interpretability in addition to common clustering objectives. We propose a <span class="math inline">\(\beta\)</span>-interpretable clustering algorithm that ensures that at least <span class="math inline">\(\beta\)</span> fraction of nodes in each cluster share the same feature value. The tunable parameter <span class="math inline">\(\beta\)</span> is user-specified. We also present a more efficient algorithm for scenarios with <span class="math inline">\(\beta\!=\!1\)</span> and analyze the theoretical guarantees of the two algorithms. Finally, we empirically demonstrate the benefits of our approaches in generating interpretable clusters using four real-world datasets. The interpretability of the clusters is complemented by generating simple explanations denoting the feature values of the nodes in the clusters, using frequent pattern mining.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08180v1" style="color: #d9230f">Deep Radar Waveform Design for Efficient Automotive Radar Sensing</a></b><br><em>Signal Processing, Machine Learning, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08180v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. …</summary><br> In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a well-known unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08111v1" style="color: #d9230f">HCNAF: Hyper-Conditioned Neural Autoregressive Flow and its Application for Probabilistic Occupancy Map Forecasting</a></b><br><em>Machine Learning, Robotics, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08111v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We introduce Hyper-Conditioned Neural Autoregressive Flow (HCNAF); a powerful universal distribution approximator designed to model arbitrarily complex conditional probability density functions. HCNAF consists of a neural-net based conditional autoregressive flow (AF) and a hyper-network that can take large conditions in non-autoregressive fashion and outputs the network parameters of the AF. …</summary><br> Like other flow models, HCNAF performs exact likelihood inference. We demonstrate the effectiveness and attributes of HCNAF, including its generalization capability over unseen conditions and show that HCNAF outperforms recent AF models in a conditional density estimation task for MNIST. We also show that HCNAF scales up to complex high-dimensional prediction problems of the magnitude of self-driving and that HCNAF yields a state-of-the-art performance in a public self-driving dataset.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07819v1" style="color: #d9230f">Angular Learning: Toward Discriminative Embedded Features</a></b><br><em>Computer Vision and Pattern Recognition, Machine Learning, Machine Learning</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07819v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The margin-based softmax loss functions greatly enhance intra-class compactness and perform well on the tasks of face recognition and object classification. Outperformance, however, depends on the careful hyperparameter selection. …</summary><br> Moreover, the hard angle restriction also increases the risk of overfitting. In this paper, angular loss suggested by maximizing the angular gradient to promote intra-class compactness avoids overfitting. Besides, our method has only one adjustable constant for intra-class compactness control. We define three metrics to measure inter-class separability and intra-class compactness. In experiments, we test our method, as well as other methods, on many well-known datasets. Experimental results reveal that our method has the superiority of accuracy improvement, discriminative information, and time-consumption.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08103v1" style="color: #d9230f">A Finite-Sample Deviation Bound for Stable Autoregressive Processes</a></b><br><em>Machine Learning, Machine Learning, Signal Processing, Statistics Theory, Statistics Theory</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08103v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this paper, we study non-asymptotic deviation bounds of the least squares estimator in Gaussian AR(<span class="math inline">\(n\)</span>) processes. By relying on martingale concentration inequalities and a tail-bound for <span class="math inline">\(\chi^2\)</span> distributed variables, we provide a concentration bound for the sample covariance matrix of the process output. …</summary><br> With this, we present a problem-dependent finite-time bound on the deviation probability of any fixed linear combination of the estimated parameters of the AR<span class="math inline">\((n)\)</span> process. We discuss extensions and limitations of our approach.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08165v1" style="color: #d9230f">Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for Python, C++, and soon more</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08165v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Cyanure is an open-source C++ software package with a Python interface. The goal of Cyanure is to provide state-of-the-art solvers for learning linear models, based on stochastic variance-reduced stochastic optimization with acceleration mechanisms. …</summary><br> Cyanure can handle a large variety of loss functions (logistic, square, squared hinge, multinomial logistic) and regularization functions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It provides a simple Python API, which is very close to that of scikit-learn, which should be extended to other languages such as R or Matlab in a near future.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08140v1" style="color: #d9230f">An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08140v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The goal of eXtreme Multi-label Learning (XML) is to design and learn a model that can automatically annotate a given data point with the most relevant subset of labels from an extremely large label set. Recently, many techniques have been proposed for XML that achieve reasonable performance on benchmark datasets. …</summary><br> Motivated by the complexities of these methods and their subsequent training requirements, in this paper we propose a simple baseline technique for this task. Precisely, we present a global feature embedding technique for XML that can easily scale to very large datasets containing millions of data points in very high-dimensional feature space, irrespective of number of samples and labels. Next we show how an ensemble of such global embeddings can be used to achieve further boost in prediction accuracies with only linear increase in training and prediction time. During testing, we assign the labels using a weighted k-nearest neighbour classifier in the embedding space. Experiments reveal that though conceptually simple, this technique achieves quite competitive results, and has training time of less than one minute using a single CPU core with 15.6 GB RAM even for large-scale datasets such as Amazon-3M.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="machine-learning--cs-lg-">Machine Learning (cs.LG)</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="24">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Machine Learning (cs.LG)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08195v1" style="color: #d9230f">Artificial Agents Learn Flexible Visual Representations by Playing a Hiding Game</a></b><br><em>Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning</em>. 8 authors. <a href="http://arxiv.org/pdf/1912.08195v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The ubiquity of embodied gameplay, observed in a wide variety of animal species including turtles and ravens, has led researchers to question what advantages play provides to the animals engaged in it. Mounting evidence suggests that play is critical in developing the neural flexibility for creative problem solving, socialization, and can improve the plasticity of the medial prefrontal cortex. …</summary><br> Comparatively little is known regarding the impact of gameplay upon embodied artificial agents. While recent work has produced artificial agents proficient in abstract games, the environments these agents act within are far removed the real world and thus these agents provide little insight into the advantages of embodied play. Hiding games have arisen in multiple cultures and species, and provide a rich ground for studying the impact of embodied gameplay on representation learning in the context of perspective taking, secret keeping, and false belief understanding. Here we are the first to show that embodied adversarial reinforcement learning agents playing cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn representations of their observations encoding information such as occlusion, object permanence, free space, and containment; on par with representations learnt by the most popular modern paradigm for visual representation learning which requires large datasets independently labeled for each new task. Our representations are enhanced by intent and memory, through interaction and play, moving closer to biologically motivated learning strategies. These results serve as a model for studying how facets of vision and perspective taking develop through play, provide an experimental framework for assessing what is learned by artificial agents, and suggest that representation learning should move from static datasets and towards experiential, interactive, learning.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08141v1" style="color: #d9230f">Performance of regression models as a function of experiment noise</a></b><br><em>Biomolecules, Machine Learning</em>. 8 authors. <a href="http://arxiv.org/pdf/1912.08141v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A challenge in developing machine learning regression models is that it is difficult to know whether maximal performance has been reached on a particular dataset, or whether further model improvement is possible. In biology this problem is particularly pronounced as sample labels are typically obtained through experiments and therefore have experiment noise associated with them. …</summary><br> Such label noise puts a fundamental limit to the performance attainable by regression models. We address this challenge by deriving a theoretical upper bound for the coefficient of determination (R2) for regression models. This theoretical upper bound depends only on the noise associated with sample labels in a dataset as well as the label variance. The upper bound estimate was validated via Monte Carlo simulations and then used as a tool to bootstrap performance of regression models trained on biological datasets, including protein sequence data, transcriptomic data, and genomic data. Although we study biological datasets in this work, the new upper bound estimates will hold true for regression models from any research field or application area where sample labels are associated with noise.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07976v1" style="color: #d9230f">A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction</a></b><br><em>Computation and Language, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07976v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Aspect-based sentiment analysis (ABSA) task is a multi-grained task of natural language processing and consists of two subtasks: aspect term extraction (ATE) and aspect polarity classification (APC). Most of the existing work focuses on the subtask of aspect term polarity inferring and ignores the significance of aspect term extraction. …</summary><br> Besides, the xisting researches do not pay attention to the research of the Chinese-oriented ABSA task. Based on the local context focus (LCF) mechanism, this paper firstly proposes a multi-task learning model for Chineseoriented aspect-based sentiment analysis, namely LCF-ATEPC. Compared with existing models, this model equips the capability of extracting aspect term and inferring aspect term polarity synchronously, moreover, this model is effective to analyze both Chinese and English comments simultaneously and the experiment on a multilingual mixed dataset proved its availability. By integrating the domain-adapted BERT model, the LCF-ATEPC model achieved the state-ofthe-art performance of aspect term extraction and aspect polarity classification in four Chinese review datasets. Besides, the experimental results on the most commonly used SemEval-2014 task4 Restaurant and Laptop datasets outperform the state-of-the-art performance on the ATE subtask.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07991v1" style="color: #d9230f">Jointly Trained Image and Video Generation using Residual Vectors</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07991v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. …</summary><br> We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach’s compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique’s capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08112v1" style="color: #d9230f">A learning-based algorithm to quickly compute good primal solutions for Stochastic Integer Programs</a></b><br><em>Optimization and Control, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08112v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We propose a novel approach using supervised learning to obtain near-optimal primal solutions for two-stage stochastic integer programming (2SIP) problems with constraints in the first and second stages. The goal of the algorithm is to predict a “representative scenario” (RS) for the problem such that, deterministically solving the 2SIP with the random realization equal to the RS, gives a near-optimal solution to the original 2SIP. …</summary><br> Predicting an RS, instead of directly predicting a solution ensures first-stage feasibility of the solution. If the problem is known to have complete recourse, second-stage feasibility is also guaranteed. For computational testing, we learn to find an RS for a two-stage stochastic facility location problem with integer variables and linear constraints in both stages and consistently provide near-optimal solutions. Our computing times are very competitive with those of general-purpose integer programming solvers to achieve a similar solution quality.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07943v1" style="color: #d9230f">Pioneer dataset and automatic recognition of Urdu handwritten characters using a deep autoencoder and convolutional neural network</a></b><br><em>Computer Vision and Pattern Recognition, Computation and Language, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07943v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Automatic recognition of Urdu handwritten digits and characters, is a challenging task. It has applications in postal address reading, bank’s cheque processing, and digitization and preservation of handwritten manuscripts from old ages. …</summary><br> While there exists a significant work for automatic recognition of handwritten English characters and other major languages of the world, the work done for Urdu lan-guage is extremely insufficient. This paper has two goals. Firstly, we introduce a pioneer dataset for handwritten digits and characters of Urdu, containing samples from more than 900 individuals. Secondly, we report results for automatic recog-nition of handwritten digits and characters as achieved by using deep auto-encoder network and convolutional neural network. More specifically, we use a two-layer and a three-layer deep autoencoder network and convolutional neural network and evaluate the two frameworks in terms of recognition accuracy. The proposed framework of deep autoencoder can successfully recognize digits and characters with an accuracy of 97% for digits only, 81% for characters only and 82% for both digits and characters simultaneously. In comparison, the framework of convolutional neural network has accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for both digits and characters simultaneously. These frameworks can serve as baselines for future research on Urdu handwritten text.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07882v1" style="color: #d9230f">Joint Interaction and Trajectory Prediction for Autonomous Driving using Graph Neural Networks</a></b><br><em>Machine Learning, Artificial Intelligence, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07882v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we aim to predict the future motion of vehicles in a traffic scene by explicitly modeling their pairwise interactions. Specifically, we propose a graph neural network that jointly predicts the discrete interaction modes and 5-second future trajectories for all agents in the scene. …</summary><br> Our model infers an interaction graph whose nodes are agents and whose edges capture the long-term interaction intents among the agents. In order to train the model to recognize known modes of interaction, we introduce an auto-labeling function to generate ground truth interaction labels. Using a large-scale real-world driving dataset, we demonstrate that jointly predicting the trajectories along with the explicit interaction types leads to significantly lower trajectory error than baseline methods. Finally, we show through simulation studies that the learned interaction modes are semantically meaningful.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07840v1" style="color: #d9230f">Cross-Lingual Ability of Multilingual BERT: An Empirical Study</a></b><br><em>Computation and Language, Artificial Intelligence, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07840v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Recent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) – surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. …</summary><br> We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages – Spanish, Hindi, and Russian – and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08136v1" style="color: #d9230f">Direction Concentration Learning: Enhancing Congruency in Machine Learning</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08136v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>One of the well-known challenges in computer vision tasks is the visual diversity of images, which could result in an agreement or disagreement between the learned knowledge and the visual content exhibited by the current observation. In this work, we first define such an agreement in a concepts learning process as congruency. …</summary><br> Formally, given a particular task and sufficiently large dataset, the congruency issue occurs in the learning process whereby the task-specific semantics in the training data are highly varying. We propose a Direction Concentration Learning (DCL) method to improve congruency in the learning process, where enhancing congruency influences the convergence path to be less circuitous. The experimental results show that the proposed DCL method generalizes to state-of-the-art models and optimizers, as well as improves the performances of saliency prediction task, continual learning task, and classification task. Moreover, it helps mitigate the catastrophic forgetting problem in the continual learning task. The code is publicly available at <a href="https://github.com/luoyan407/congruency" class="uri">https://github.com/luoyan407/congruency</a>.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08113v1" style="color: #d9230f">Improved Surrogates in Inertial Confinement Fusion with Manifold and Cycle Consistencies</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Computational Physics, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08113v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Neural networks have become very popular in surrogate modeling because of their ability to characterize arbitrary, high dimensional functions in a data driven fashion. This paper advocates for the training of surrogates that are consistent with the physical manifold – i. …</summary><br>e., predictions are always physically meaningful, and are cyclically consistent – i.e., when the predictions of the surrogate, when passed through an independently trained inverse model give back the original input parameters. We find that these two consistencies lead to surrogates that are superior in terms of predictive performance, more resilient to sampling artifacts, and tend to be more data efficient. Using Inertial Confinement Fusion (ICF) as a test bed problem, we model a 1D semi-analytic numerical simulator and demonstrate the effectiveness of our approach. Code and data are available at <a href="https://github.com/rushilanirudh/macc/" class="uri">https://github.com/rushilanirudh/macc/</a>
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08177v1" style="color: #d9230f">Lift &amp; Learn: Physics-informed machine learning for large-scale nonlinear dynamical systems</a></b><br><em>Numerical Analysis, Machine Learning, Numerical Analysis</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08177v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We present Lift &amp; Learn, a physics-informed method for learning low-dimensional models for large-scale dynamical systems. The method exploits knowledge of a system’s governing equations to identify a coordinate transformation in which the system dynamics have quadratic structure. …</summary><br> This transformation is called a lifting map because it often adds auxiliary variables to the system state. The lifting map is applied to data obtained by evaluating a model for the original nonlinear system. This lifted data is projected onto its leading principal components, and low-dimensional linear and quadratic matrix operators are fit to the lifted reduced data using a least-squares operator inference procedure. Analysis of our method shows that the Lift &amp; Learn models are able to capture the system physics in the lifted coordinates at least as accurately as traditional intrusive model reduction approaches. This preservation of system physics makes the Lift &amp; Learn models robust to changes in inputs. Numerical experiments on the FitzHugh-Nagumo neuron activation model and the compressible Euler equations demonstrate the generalizability of our model.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07936v1" style="color: #d9230f">Probabilistic Software Modeling: A Data-driven Paradigm for Software Analysis</a></b><br><em>Software Engineering, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07936v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Software systems are complex, and behavioral comprehension with the increasing amount of AI components challenges traditional testing and maintenance strategies.The lack of tools and methodologies for behavioral software comprehension leaves developers to testing and debugging that work in the boundaries of known scenarios. …</summary><br> We present Probabilistic Software Modeling (PSM), a data-driven modeling paradigm for predictive and generative methods in software engineering. PSM analyzes a program and synthesizes a network of probabilistic models that can simulate and quantify the original program’s behavior. The approach extracts the type, executable, and property structure of a program and copies its topology. Each model is then optimized towards the observed runtime leading to a network that reflects the system’s structure and behavior. The resulting network allows for the full spectrum of statistical inferential analysis with which rich predictive and generative applications can be built. Applications range from the visualization of states, inferential queries, test case generation, and anomaly detection up to the stochastic execution of the modeled system. In this work, we present the modeling methodologies, an empirical study of the runtime behavior of software systems, and a comprehensive study on PSM modeled systems. Results indicate that PSM is a solid foundation for structural and behavioral software comprehension applications.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08001v1" style="color: #d9230f">Sim-to-Real Domain Adaptation For High Energy Physics</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08001v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Particle physics or High Energy Physics (HEP) studies the elementary constituents of matter and their interactions with each other. Machine Learning (ML) has played an important role in HEP analysis and has proven extremely successful in this area. …</summary><br> Usually, the ML algorithms are trained on numerical simulations of the experimental setup and then applied to the real experimental data. However, any discrepancy between the simulation and real data may lead to dramatic consequences concerning the performances of the algorithm on real data. In this paper, we present an application of domain adaptation using a Domain Adversarial Neural Network trained on public HEP data. We demonstrate the success of this approach to achieve sim-to-real transfer and ensure the consistency of the ML algorithms performances on real and simulated HEP datasets.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07999v1" style="color: #d9230f">Embedded Constrained Feature Construction for High-Energy Physics Data Classification</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07999v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Before any publication, data analysis of high-energy physics experiments must be validated. This validation is granted only if a perfect understanding of the data and the analysis process is demonstrated. …</summary><br> Therefore, physicists prefer using transparent machine learning algorithms whose performances highly rely on the suitability of the provided input features. To transform the feature space, feature construction aims at automatically generating new relevant features. Whereas most of previous works in this area perform the feature construction prior to the model training, we propose here a general framework to embed a feature construction technique adapted to the constraints of high-energy physics in the induction of tree-based models. Experiments on two high-energy physics datasets confirm that a significant gain is obtained on the classification scores, while limiting the number of built features. Since the features are built to be interpretable, the whole model is transparent and readable.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08142v1" style="color: #d9230f">Causality matters in medical imaging</a></b><br><em>Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08142v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>This article discusses how the language of causality can shed new light on the major challenges in machine learning for medical imaging: 1) data scarcity, which is the limited availability of high-quality annotations, and 2) data mismatch, whereby a trained algorithm may fail to generalize in clinical practice. Looking at these challenges through the lens of causality allows decisions about data collection, annotation procedures, and learning strategies to be made (and scrutinized) more transparently. …</summary><br> We discuss how causal relationships between images and annotations can not only have profound effects on the performance of predictive models, but may even dictate which learning strategies should be considered in the first place. For example, we conclude that semi-supervision may be unsuitable for image segmentation—one of the possibly surprising insights from our causal analysis, which is illustrated with representative real-world examples of computer-aided diagnosis (skin lesion classification in dermatology) and radiotherapy (automated contouring of tumours). We highlight that being aware of and accounting for the causal relationships in medical imaging data is important for the safe development of machine learning and essential for regulation and responsible reporting. To facilitate this we provide step-by-step recommendations for future studies.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07820v1" style="color: #d9230f">Balancing the Tradeoff Between Clustering Value and Interpretability</a></b><br><em>Machine Learning, Data Structures and Algorithms, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07820v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Graph clustering groups entities – the vertices of a graph – based on their similarity, typically using a complex distance function over a large number of features. Successful integration of clustering approaches in automated decision-support systems hinges on the interpretability of the resulting clusters. …</summary><br> This paper addresses the problem of generating interpretable clusters, given features of interest that signify interpretability to an end-user, by optimizing interpretability in addition to common clustering objectives. We propose a <span class="math inline">\(\beta\)</span>-interpretable clustering algorithm that ensures that at least <span class="math inline">\(\beta\)</span> fraction of nodes in each cluster share the same feature value. The tunable parameter <span class="math inline">\(\beta\)</span> is user-specified. We also present a more efficient algorithm for scenarios with <span class="math inline">\(\beta\!=\!1\)</span> and analyze the theoretical guarantees of the two algorithms. Finally, we empirically demonstrate the benefits of our approaches in generating interpretable clusters using four real-world datasets. The interpretability of the clusters is complemented by generating simple explanations denoting the feature values of the nodes in the clusters, using frequent pattern mining.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08189v1" style="color: #d9230f">Supervised learning algorithms resilient to discriminatory data perturbations</a></b><br><em>Machine Learning, Computers and Society, Physics and Society</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08189v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The actions of individuals can be discriminatory with respect to certain protected attributes, such as race or sex. Recently, discrimination has become a focal concern in supervised learning algorithms augmenting human decision-making. …</summary><br> These systems are trained using historical data, which may have been tainted by discrimination, and may learn biases against the protected groups. An important question is how to train models without propagating discrimination. Such discrimination can be either direct, when one or more of protected attributes are used in the decision-making directly, or indirect, when other attributes correlated with the protected attributes are used in an unjustified manner. In this work, we i) model discrimination as a perturbation of data-generating process; ii) introduce a measure of resilience of a supervised learning algorithm to potentially discriminatory data perturbations; and iii) propose a novel supervised learning method that is more resilient to such discriminatory perturbations than state-of-the-art learning algorithms addressing discrimination. The proposed method can be used with general supervised learning algorithms, prevents direct discrimination and avoids inducement of indirect discrimination, while maximizing model accuracy.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08180v1" style="color: #d9230f">Deep Radar Waveform Design for Efficient Automotive Radar Sensing</a></b><br><em>Signal Processing, Machine Learning, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08180v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. …</summary><br> In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a well-known unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08111v1" style="color: #d9230f">HCNAF: Hyper-Conditioned Neural Autoregressive Flow and its Application for Probabilistic Occupancy Map Forecasting</a></b><br><em>Machine Learning, Robotics, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08111v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We introduce Hyper-Conditioned Neural Autoregressive Flow (HCNAF); a powerful universal distribution approximator designed to model arbitrarily complex conditional probability density functions. HCNAF consists of a neural-net based conditional autoregressive flow (AF) and a hyper-network that can take large conditions in non-autoregressive fashion and outputs the network parameters of the AF. …</summary><br> Like other flow models, HCNAF performs exact likelihood inference. We demonstrate the effectiveness and attributes of HCNAF, including its generalization capability over unseen conditions and show that HCNAF outperforms recent AF models in a conditional density estimation task for MNIST. We also show that HCNAF scales up to complex high-dimensional prediction problems of the magnitude of self-driving and that HCNAF yields a state-of-the-art performance in a public self-driving dataset.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07819v1" style="color: #d9230f">Angular Learning: Toward Discriminative Embedded Features</a></b><br><em>Computer Vision and Pattern Recognition, Machine Learning, Machine Learning</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07819v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The margin-based softmax loss functions greatly enhance intra-class compactness and perform well on the tasks of face recognition and object classification. Outperformance, however, depends on the careful hyperparameter selection. …</summary><br> Moreover, the hard angle restriction also increases the risk of overfitting. In this paper, angular loss suggested by maximizing the angular gradient to promote intra-class compactness avoids overfitting. Besides, our method has only one adjustable constant for intra-class compactness control. We define three metrics to measure inter-class separability and intra-class compactness. In experiments, we test our method, as well as other methods, on many well-known datasets. Experimental results reveal that our method has the superiority of accuracy improvement, discriminative information, and time-consumption.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07829v1" style="color: #d9230f">Defects Mitigation in Resistive Crossbars for Analog Vector Matrix Multiplication</a></b><br><em>Emerging Technologies, Machine Learning</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07829v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>With storage and computation happening at the same place, computing in resistive crossbars minimizes data movement and avoids the memory bottleneck issue. It leads to ultra-high energy efficiency for data-intensive applications. …</summary><br> However, defects in crossbars severely affect computing accuracy. Existing solutions, including re-training with defects and redundant designs, but they have limitations in practical implementations. In this work, we introduce row shuffling and output compensation to mitigate defects without re-training or redundant resistive crossbars. We also analyzed the coupling effects of defects and circuit parasitics. Moreover, We study different combinations of methods to achieve the best trade-off between cost and performance. Our proposed methods could rescue up to 10% of defects in ResNet-20 application without performance degradation.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08103v1" style="color: #d9230f">A Finite-Sample Deviation Bound for Stable Autoregressive Processes</a></b><br><em>Machine Learning, Machine Learning, Signal Processing, Statistics Theory, Statistics Theory</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08103v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this paper, we study non-asymptotic deviation bounds of the least squares estimator in Gaussian AR(<span class="math inline">\(n\)</span>) processes. By relying on martingale concentration inequalities and a tail-bound for <span class="math inline">\(\chi^2\)</span> distributed variables, we provide a concentration bound for the sample covariance matrix of the process output. …</summary><br> With this, we present a problem-dependent finite-time bound on the deviation probability of any fixed linear combination of the estimated parameters of the AR<span class="math inline">\((n)\)</span> process. We discuss extensions and limitations of our approach.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08165v1" style="color: #d9230f">Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for Python, C++, and soon more</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08165v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Cyanure is an open-source C++ software package with a Python interface. The goal of Cyanure is to provide state-of-the-art solvers for learning linear models, based on stochastic variance-reduced stochastic optimization with acceleration mechanisms. …</summary><br> Cyanure can handle a large variety of loss functions (logistic, square, squared hinge, multinomial logistic) and regularization functions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It provides a simple Python API, which is very close to that of scikit-learn, which should be extended to other languages such as R or Matlab in a near future.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08140v1" style="color: #d9230f">An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08140v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The goal of eXtreme Multi-label Learning (XML) is to design and learn a model that can automatically annotate a given data point with the most relevant subset of labels from an extremely large label set. Recently, many techniques have been proposed for XML that achieve reasonable performance on benchmark datasets. …</summary><br> Motivated by the complexities of these methods and their subsequent training requirements, in this paper we propose a simple baseline technique for this task. Precisely, we present a global feature embedding technique for XML that can easily scale to very large datasets containing millions of data points in very high-dimensional feature space, irrespective of number of samples and labels. Next we show how an ensemble of such global embeddings can be used to achieve further boost in prediction accuracies with only linear increase in training and prediction time. During testing, we assign the labels using a weighted k-nearest neighbour classifier in the embedding space. Experiments reveal that though conceptually simple, this technique achieves quite competitive results, and has training time of less than one minute using a single CPU core with 15.6 GB RAM even for large-scale datasets such as Amazon-3M.
</details>
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="data-science-arxiv-by-primary-tag">Data Science arXiv by Primary Tag</h2>
<p>The tables below show abstracts organized by category with hyperlinks back to the arXiv site.</p>
<div class="layout-chunk" data-layout="l-page">

<h3 id="computer-science">Computer Science</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="8">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Computer Vision and Pattern Recognition (cs.CV)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08166v1" style="color: #d9230f">APRICOT: A Dataset of Physical Adversarial Attacks on Object Detection</a></b><br><em>Computer Vision and Pattern Recognition</em>. 9 authors. <a href="http://arxiv.org/pdf/1912.08166v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Physical adversarial attacks threaten to fool object detection systems, but reproducible research on the real-world effectiveness of physical patches and how to defend against them requires a publicly available benchmark dataset. We present APRICOT, a collection of over 1,000 annotated photographs of printed adversarial patches in public locations. …</summary><br> The patches target several object categories for three COCO-trained detection models, and the photos represent natural variation in position, distance, lighting conditions, and viewing angle. Our analysis suggests that maintaining adversarial robustness in uncontrolled settings is highly challenging, but it is still possible to produce targeted detections under white-box and sometimes black-box settings. We establish baselines for defending against adversarial patches through several methods, including a detector supervised with synthetic data and unsupervised methods such as kernel density estimation, Bayesian uncertainty, and reconstruction error. Our results suggest that adversarial patches can be effectively flagged, both in a high-knowledge, attack-specific scenario, and in an unsupervised setting where patches are detected as anomalies in natural images. This dataset and the described experiments provide a benchmark for future research on the effectiveness of and defenses against physical adversarial objects in the wild.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07821v1" style="color: #d9230f">Valley-Coupled-Spintronic Non-Volatile Memories with Compute-In-Memory Support</a></b><br><em>Emerging Technologies, Applied Physics</em>. 9 authors. <a href="http://arxiv.org/pdf/1912.07821v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we propose valley-coupled spin-hall memories (VSH-MRAMs) based on monolayer WSe2. The key features of the proposed memories are (a) the ability to switch magnets with perpendicular magnetic anisotropy (PMA) via VSH effect and (b) an integrated gate that can modulate the charge/spin current (IC/IS) flow. …</summary><br> The former attribute results in high energy efficiency (compared to the Giant-Spin Hall (GSH) effect-based devices with in-plane magnetic anisotropy (IMA) magnets). The latter feature leads to a compact access transistor-less memory array design. We experimentally measure the gate controllability of the current as well as the nonlocal resistance associated with VSH effect. Based on the measured data, we develop a simulation framework (using physical equations) to propose and analyze single-ended and differential VSH effect based magnetic memories (VSH-MRAM and DVSH-MRAM, respectively). At the array level, the proposed VSH/DVSH-MRAMs achieve 50%/ 11% lower write time, 59%/ 67% lower write energy and 35%/ 41% lower read energy at iso-sense margin, compared to single ended/differential (GSH/DGSH)-MRAMs. System level evaluation in the context of general purpose processor and intermittently-powered system shows up to 3.14X and 1.98X better energy efficiency for the proposed (D)VSH-MRAMs over (D)GSH-MRAMs respectively. Further, the differential sensing of the proposed DVSH-MRAM leads to natural and simultaneous in-memory computation of bit-wise AND and NOR logic functions. Using this feature, we design a computation-in-memory (CiM) architecture that performs Boolean logic and addition (ADD) with a single array access. System analysis performed by integrating our DVSH-MRAM: CiM in the Nios II processor across various application benchmarks shows up to 2.66X total energy savings, compared to DGSH-MRAM: CiM.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08195v1" style="color: #d9230f">Artificial Agents Learn Flexible Visual Representations by Playing a Hiding Game</a></b><br><em>Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning</em>. 8 authors. <a href="http://arxiv.org/pdf/1912.08195v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The ubiquity of embodied gameplay, observed in a wide variety of animal species including turtles and ravens, has led researchers to question what advantages play provides to the animals engaged in it. Mounting evidence suggests that play is critical in developing the neural flexibility for creative problem solving, socialization, and can improve the plasticity of the medial prefrontal cortex. …</summary><br> Comparatively little is known regarding the impact of gameplay upon embodied artificial agents. While recent work has produced artificial agents proficient in abstract games, the environments these agents act within are far removed the real world and thus these agents provide little insight into the advantages of embodied play. Hiding games have arisen in multiple cultures and species, and provide a rich ground for studying the impact of embodied gameplay on representation learning in the context of perspective taking, secret keeping, and false belief understanding. Here we are the first to show that embodied adversarial reinforcement learning agents playing cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn representations of their observations encoding information such as occlusion, object permanence, free space, and containment; on par with representations learnt by the most popular modern paradigm for visual representation learning which requires large datasets independently labeled for each new task. Our representations are enhanced by intent and memory, through interaction and play, moving closer to biologically motivated learning strategies. These results serve as a model for studying how facets of vision and perspective taking develop through play, provide an experimental framework for assessing what is learned by artificial agents, and suggest that representation learning should move from static datasets and towards experiential, interactive, learning.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07817v1" style="color: #d9230f">Prema: A Tool for Precise Requirements Editing, Modeling and Analysis</a></b><br><em>Formal Languages and Automata Theory, Software Engineering</em>. 8 authors. <a href="http://arxiv.org/pdf/1912.07817v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We present Prema, a tool for Precise Requirement Editing, Modeling and Analysis. It can be used in various fields for describing precise requirements using formal notations and performing rigorous analysis. …</summary><br> By parsing the requirements written in formal modeling language, Prema is able to get a model which aptly depicts the requirements. It also provides different rigorous verification and validation techniques to check whether the requirements meet users’ expectation and find potential errors. We show that our tool can provide a unified environment for writing and verifying requirements without using tools that are not well inter-related. For experimental demonstration, we use the requirements of the automatic train protection (ATP) system of CASCO signal co. LTD., the largest railway signal control system manufacturer of China. The code of the tool cannot be released here because the project is commercially confidential. However, a demonstration video of the tool is available at <a href="https://youtu.be/BX0yv8pRMWs" class="uri">https://youtu.be/BX0yv8pRMWs</a>.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07794v1" style="color: #d9230f">Towards Smart Radio Environment for Wireless Communications via Intelligent Reflecting Surfaces: A Comprehensive Survey</a></b><br><em>Information Theory, Emerging Technologies, Information Theory</em>. 7 authors. <a href="http://arxiv.org/pdf/1912.07794v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>This paper presents a comprehensive literature review on applications and design aspects of the intelligent reflecting surface (IRS) in the future wireless networks. Conventionally, the network optimization has been limited to transmission control at two endpoints, i. …</summary><br>e., end users and network controller. The fading wireless channel is uncontrollable and becomes one of the main limiting factors for performance improvement. The IRS is composed of a large array of scattering elements, which can be individually configured to generate additional phase shifts to the signal reflections. Hence, it can actively control the signal propagation properties in favor of signal reception, and thus realize the notion of a smart radio environment. As such, the IRS’s phase control combined with the conventional transmission control can potentially bring performance gain compared to the conventional wireless networks without using the IRS. In this survey, we first introduce basic concepts of the IRS and the realizations of its reconfigurability. Then, we focus on applications of the IRS in wireless communications. We overview different performance metrics and analytical approaches to characterize the performance improvement of IRS-assisted wireless networks. To exploit the performance gain, we discuss the joint optimization of the IRS’s phase control and the transceivers’ transmission control in different network design problems, e.g., rate maximization and power minimization problems. Furthermore, we extend the discussion of IRS-assisted wireless networks to some emerging wireless applications. Finally, we highlight important practical challenges and future research directions of realizing IRS-assisted wireless communications in beyond 5G networks.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07976v1" style="color: #d9230f">A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction</a></b><br><em>Computation and Language, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07976v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Aspect-based sentiment analysis (ABSA) task is a multi-grained task of natural language processing and consists of two subtasks: aspect term extraction (ATE) and aspect polarity classification (APC). Most of the existing work focuses on the subtask of aspect term polarity inferring and ignores the significance of aspect term extraction. …</summary><br> Besides, the xisting researches do not pay attention to the research of the Chinese-oriented ABSA task. Based on the local context focus (LCF) mechanism, this paper firstly proposes a multi-task learning model for Chineseoriented aspect-based sentiment analysis, namely LCF-ATEPC. Compared with existing models, this model equips the capability of extracting aspect term and inferring aspect term polarity synchronously, moreover, this model is effective to analyze both Chinese and English comments simultaneously and the experiment on a multilingual mixed dataset proved its availability. By integrating the domain-adapted BERT model, the LCF-ATEPC model achieved the state-ofthe-art performance of aspect term extraction and aspect polarity classification in four Chinese review datasets. Besides, the experimental results on the most commonly used SemEval-2014 task4 Restaurant and Laptop datasets outperform the state-of-the-art performance on the ATE subtask.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07796v1" style="color: #d9230f">A Comprehensive Review of Shepherding as a Bio-inspired Swarm-Robotics Guidance Approach</a></b><br><em>Robotics, Artificial Intelligence, Systems and Control</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07796v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The simultaneous control of multiple coordinated robotic agents represents an elaborate problem. If solved, however, the interaction between the agents can lead to solutions to sophisticated problems. …</summary><br> The concept of swarming, inspired by nature, can be described as the emergence of complex system-level behaviors from the interactions of relatively elementary agents. Due to the effectiveness of solutions found in nature, bio-inspired swarming-based control techniques are receiving a lot of attention in robotics. One method, known as swarm shepherding, is founded on the sheep herding behavior exhibited by sheepdogs, where a swarm of relatively simple agents are governed by a shepherd (or shepherds) which is responsible for high-level guidance and planning. Many studies have been conducted on shepherding as a control technique, ranging from the replication of sheep herding via simulation, to the control of uninhabited vehicles and robots for a variety of applications. We present a comprehensive review of the literature on swarm shepherding to reveal the advantages and potential of the approach to be applied to a plethora of robotic systems in the future.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08035v1" style="color: #d9230f">Single-Stage Monocular 3D Object Detection with Virtual Cameras</a></b><br><em>Computer Vision and Pattern Recognition</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08035v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>While expensive LiDAR and stereo camera rigs have enabled the development of successful 3D object detection methods, monocular RGB-only approaches still lag significantly behind. Our work advances the state of the art by introducing MoVi-3D, a novel, single-stage deep architecture for monocular 3D object detection. …</summary><br> At its core, MoVi-3D leverages geometrical information to generate synthetic views from virtual cameras at both, training and test time, resulting in normalized object appearance with respect to distance. Our synthetically generated views facilitate the detection task as they cut down the variability in visual appearance associated to objects placed at different distances from the camera. As a consequence, the deep model is relieved from learning depth-specific representations and its complexity can be significantly reduced. In particular we show that our proposed concept of exploiting virtual cameras enables us to set new state-of-the-art results on the popular KITTI3D benchmark using just a lightweight, single-stage architecture.
</details>
</td>
</tr>
<tr grouplength="8">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Machine Learning (cs.LG)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07991v1" style="color: #d9230f">Jointly Trained Image and Video Generation using Residual Vectors</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07991v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. …</summary><br> We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach’s compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique’s capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08066v1" style="color: #d9230f">Putting Ridesharing to the Test: Efficient and Scalable Solutions and the Power of Dynamic Vehicle Relocation</a></b><br><em>Multiagent Systems, Data Structures and Algorithms</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08066v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Ridesharing is a coordination problem in its core. Traditionally it has been solved in a centralized manner by ridesharing platforms. …</summary><br> Yet, to truly allow for scalable solutions, we needs to shift from traditional approaches, to multi-agent systems, ideally run on-device. In this paper, we show that a recently proposed heuristic (ALMA), which exhibits such properties, offers an efficient, end-to-end solution for the ridesharing problem. Moreover, by utilizing simple relocation schemes we significantly improve QoS metrics, by up to 50%. To demonstrate the latter, we perform a systematic evaluation of a diverse set of algorithms for the ridesharing problem, which is, to the best of our knowledge, one of the largest and most comprehensive to date. Our evaluation setting is specifically designed to resemble reality as closely as possible. In particular, we evaluate 12 different algorithms over 12 metrics related to global efficiency, complexity, passenger, driver, and platform incentives.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07943v1" style="color: #d9230f">Pioneer dataset and automatic recognition of Urdu handwritten characters using a deep autoencoder and convolutional neural network</a></b><br><em>Computer Vision and Pattern Recognition, Computation and Language, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07943v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Automatic recognition of Urdu handwritten digits and characters, is a challenging task. It has applications in postal address reading, bank’s cheque processing, and digitization and preservation of handwritten manuscripts from old ages. …</summary><br> While there exists a significant work for automatic recognition of handwritten English characters and other major languages of the world, the work done for Urdu lan-guage is extremely insufficient. This paper has two goals. Firstly, we introduce a pioneer dataset for handwritten digits and characters of Urdu, containing samples from more than 900 individuals. Secondly, we report results for automatic recog-nition of handwritten digits and characters as achieved by using deep auto-encoder network and convolutional neural network. More specifically, we use a two-layer and a three-layer deep autoencoder network and convolutional neural network and evaluate the two frameworks in terms of recognition accuracy. The proposed framework of deep autoencoder can successfully recognize digits and characters with an accuracy of 97% for digits only, 81% for characters only and 82% for both digits and characters simultaneously. In comparison, the framework of convolutional neural network has accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for both digits and characters simultaneously. These frameworks can serve as baselines for future research on Urdu handwritten text.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07840v1" style="color: #d9230f">Cross-Lingual Ability of Multilingual BERT: An Empirical Study</a></b><br><em>Computation and Language, Artificial Intelligence, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07840v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Recent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) – surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. …</summary><br> We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages – Spanish, Hindi, and Russian – and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07827v1" style="color: #d9230f">ORC Layout: Adaptive GUI Layout with OR-Constraints</a></b><br><em>Human-Computer Interaction, Graphics</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07827v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. …</summary><br> We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07804v1" style="color: #d9230f">LTLf Synthesis with Fairness and Stability Assumptions</a></b><br><em>Artificial Intelligence, Formal Languages and Automata Theory, Computer Science and Game Theory, Logic in Computer Science</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07804v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In synthesis, assumptions are constraints on the environment that rule out certain environment behaviors. A key observation here is that even if we consider systems with LTLf goals on finite traces, environment assumptions need to be expressed over infinite traces, since accomplishing the agent goals may require an unbounded number of environment action. …</summary><br> To solve synthesis with respect to finite-trace LTLf goals under infinite-trace assumptions, we could reduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and in LTL have the same worst-case complexity (both 2EXPTIME-complete), the algorithms available for LTL synthesis are much more difficult in practice than those for LTLf synthesis. In this work we show that in interesting cases we can avoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis. Specifically, we develop a BDD-based fixpoint-based technique for handling basic forms of fairness and of stability assumptions. We show, empirically, that this technique performs much better than standard LTL synthesis.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08193v1" style="color: #d9230f">PointRend: Image Segmentation as Rendering</a></b><br><em>Computer Vision and Pattern Recognition</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08193v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We present a new method for efficient high-quality image segmentation of objects and scenes. By analogizing classical computer graphics methods for efficient rendering with over- and undersampling challenges faced in pixel labeling tasks, we develop a unique perspective of image segmentation as a rendering problem. …</summary><br> From this vantage, we present the PointRend (Point-based Rendering) neural network module: a module that performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm. PointRend can be flexibly applied to both instance and semantic segmentation tasks by building on top of existing state-of-the-art models. While many concrete implementations of the general idea are possible, we show that a simple design already achieves excellent results. Qualitatively, PointRend outputs crisp object boundaries in regions that are over-smoothed by previous methods. Quantitatively, PointRend yields significant gains on COCO and Cityscapes, for both instance and semantic segmentation. PointRend’s efficiency enables output resolutions that are otherwise impractical in terms of memory or computation compared to existing approaches.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08136v1" style="color: #d9230f">Direction Concentration Learning: Enhancing Congruency in Machine Learning</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08136v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>One of the well-known challenges in computer vision tasks is the visual diversity of images, which could result in an agreement or disagreement between the learned knowledge and the visual content exhibited by the current observation. In this work, we first define such an agreement in a concepts learning process as congruency. …</summary><br> Formally, given a particular task and sufficiently large dataset, the congruency issue occurs in the learning process whereby the task-specific semantics in the training data are highly varying. We propose a Direction Concentration Learning (DCL) method to improve congruency in the learning process, where enhancing congruency influences the convergence path to be less circuitous. The experimental results show that the proposed DCL method generalizes to state-of-the-art models and optimizers, as well as improves the performances of saliency prediction task, continual learning task, and classification task. Moreover, it helps mitigate the catastrophic forgetting problem in the continual learning task. The code is publicly available at <a href="https://github.com/luoyan407/congruency" class="uri">https://github.com/luoyan407/congruency</a>.
</details>
</td>
</tr>
<tr grouplength="3">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Artificial Intelligence (cs.AI)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08113v1" style="color: #d9230f">Improved Surrogates in Inertial Confinement Fusion with Manifold and Cycle Consistencies</a></b><br><em>Machine Learning, Computer Vision and Pattern Recognition, Computational Physics, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08113v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Neural networks have become very popular in surrogate modeling because of their ability to characterize arbitrary, high dimensional functions in a data driven fashion. This paper advocates for the training of surrogates that are consistent with the physical manifold – i. …</summary><br>e., predictions are always physically meaningful, and are cyclically consistent – i.e., when the predictions of the surrogate, when passed through an independently trained inverse model give back the original input parameters. We find that these two consistencies lead to surrogates that are superior in terms of predictive performance, more resilient to sampling artifacts, and tend to be more data efficient. Using Inertial Confinement Fusion (ICF) as a test bed problem, we model a 1D semi-analytic numerical simulator and demonstrate the effectiveness of our approach. Code and data are available at <a href="https://github.com/rushilanirudh/macc/" class="uri">https://github.com/rushilanirudh/macc/</a>
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07936v1" style="color: #d9230f">Probabilistic Software Modeling: A Data-driven Paradigm for Software Analysis</a></b><br><em>Software Engineering, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07936v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Software systems are complex, and behavioral comprehension with the increasing amount of AI components challenges traditional testing and maintenance strategies.The lack of tools and methodologies for behavioral software comprehension leaves developers to testing and debugging that work in the boundaries of known scenarios. …</summary><br> We present Probabilistic Software Modeling (PSM), a data-driven modeling paradigm for predictive and generative methods in software engineering. PSM analyzes a program and synthesizes a network of probabilistic models that can simulate and quantify the original program’s behavior. The approach extracts the type, executable, and property structure of a program and copies its topology. Each model is then optimized towards the observed runtime leading to a network that reflects the system’s structure and behavior. The resulting network allows for the full spectrum of statistical inferential analysis with which rich predictive and generative applications can be built. Applications range from the visualization of states, inferential queries, test case generation, and anomaly detection up to the stochastic execution of the modeled system. In this work, we present the modeling methodologies, an empirical study of the runtime behavior of software systems, and a comprehensive study on PSM modeled systems. Results indicate that PSM is a solid foundation for structural and behavioral software comprehension applications.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08001v1" style="color: #d9230f">Sim-to-Real Domain Adaptation For High Energy Physics</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08001v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Particle physics or High Energy Physics (HEP) studies the elementary constituents of matter and their interactions with each other. Machine Learning (ML) has played an important role in HEP analysis and has proven extremely successful in this area. …</summary><br> Usually, the ML algorithms are trained on numerical simulations of the experimental setup and then applied to the real experimental data. However, any discrepancy between the simulation and real data may lead to dramatic consequences concerning the performances of the algorithm on real data. In this paper, we present an application of domain adaptation using a Domain Adversarial Neural Network trained on public HEP data. We demonstrate the success of this approach to achieve sim-to-real transfer and ensure the consistency of the ML algorithms performances on real and simulated HEP datasets.
</details>
</td>
</tr>
<tr grouplength="2">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Computation and Language (cs.CL)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07999v1" style="color: #d9230f">Embedded Constrained Feature Construction for High-Energy Physics Data Classification</a></b><br><em>Machine Learning, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07999v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Before any publication, data analysis of high-energy physics experiments must be validated. This validation is granted only if a perfect understanding of the data and the analysis process is demonstrated. …</summary><br> Therefore, physicists prefer using transparent machine learning algorithms whose performances highly rely on the suitability of the provided input features. To transform the feature space, feature construction aims at automatically generating new relevant features. Whereas most of previous works in this area perform the feature construction prior to the model training, we propose here a general framework to embed a feature construction technique adapted to the constraints of high-energy physics in the induction of tree-based models. Experiments on two high-energy physics datasets confirm that a significant gain is obtained on the classification scores, while limiting the number of built features. Since the features are built to be interpretable, the whole model is transparent and readable.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07834v1" style="color: #d9230f">Design and Implementation of Linked Planning Domain Definition Language</a></b><br><em>Artificial Intelligence, Logic in Computer Science, Robotics</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07834v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Planning is a critical component of any artificial intelligence system that concerns the realization of strategies or action sequences typically for intelligent agents and autonomous robots. Given predefined parameterized actions, a planning service should accept a query with the goal and initial state to give a solution with a sequence of actions applied to environmental objects. …</summary><br> This paper addresses the problem by providing a repository of actions generically applicable to various environmental objects based on Semantic Web technologies. Ontologies are used for asserting constraints in common sense as well as for resolving compatibilities between actions and states. Constraints are defined using Web standards such as SPARQL and SHACL to allow conditional predicates. We demonstrate the usefulness of the proposed planning domain description language with our robotics applications.
</details>
</td>
</tr>
<tr grouplength="2">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Emerging Technologies (cs.ET)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08059v1" style="color: #d9230f">Feature Fusion Use Unsupervised Prior Knowledge to Let Small Object Represent</a></b><br><em>Computer Vision and Pattern Recognition</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08059v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Fusing low level and high level features is a widely used strategy to provide details that might be missing during convolution and pooling. Different from previous works, we propose a new fusion mechanism called FillIn which takes advantage of prior knowledge described with superpixel segmentation. …</summary><br> According to the prior knowledge, the FillIn chooses small region on low level feature map to fill into high level feature map. By using the proposed fusion mechanism, the low level features have equal channels for some tiny region as high level features, which makes the low level features have relatively independent power to decide final semantic label. We demonstrate the effectiveness of our model on PASCAL VOC 2012, it achieves competitive test result based on DeepLabv3+ backbone and visualizations of predictions prove our fusion can let small objects represent and low level features have potential for segmenting small objects.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07971v1" style="color: #d9230f">Conditional Generative ConvNets for Exemplar-based Texture Synthesis</a></b><br><em>Computer Vision and Pattern Recognition</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07971v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The goal of exemplar-based texture synthesis is to generate texture images that are visually similar to a given exemplar. Recently, promising results have been reported by methods relying on convolutional neural networks (ConvNets) pretrained on large-scale image datasets. …</summary><br> However, these methods have difficulties in synthesizing image textures with non-local structures and extending to dynamic or sound textures. In this paper, we present a conditional generative ConvNet (cgCNN) model which combines deep statistics and the probabilistic framework of generative ConvNet (gCNN) model. Given a texture exemplar, the cgCNN model defines a conditional distribution using deep statistics of a ConvNet, and synthesize new textures by sampling from the conditional distribution. In contrast to previous deep texture models, the proposed cgCNN dose not rely on pre-trained ConvNets but learns the weights of ConvNets for each input exemplar instead. As a result, the cgCNN model can synthesize high quality dynamic, sound and image textures in a unified manner. We also explore the theoretical connections between our model and other texture models. Further investigations show that the cgCNN model can be easily generalized to texture expansion and inpainting. Extensive experiments demonstrate that our model can achieve better or at least comparable results than the state-of-the-art methods.
</details>
</td>
</tr>
<tr grouplength="2">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Software Engineering (cs.SE)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08189v1" style="color: #d9230f">Supervised learning algorithms resilient to discriminatory data perturbations</a></b><br><em>Machine Learning, Computers and Society, Physics and Society</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08189v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The actions of individuals can be discriminatory with respect to certain protected attributes, such as race or sex. Recently, discrimination has become a focal concern in supervised learning algorithms augmenting human decision-making. …</summary><br> These systems are trained using historical data, which may have been tainted by discrimination, and may learn biases against the protected groups. An important question is how to train models without propagating discrimination. Such discrimination can be either direct, when one or more of protected attributes are used in the decision-making directly, or indirect, when other attributes correlated with the protected attributes are used in an unjustified manner. In this work, we i) model discrimination as a perturbation of data-generating process; ii) introduce a measure of resilience of a supervised learning algorithm to potentially discriminatory data perturbations; and iii) propose a novel supervised learning method that is more resilient to such discriminatory perturbations than state-of-the-art learning algorithms addressing discrimination. The proposed method can be used with general supervised learning algorithms, prevents direct discrimination and avoids inducement of indirect discrimination, while maximizing model accuracy.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08111v1" style="color: #d9230f">HCNAF: Hyper-Conditioned Neural Autoregressive Flow and its Application for Probabilistic Occupancy Map Forecasting</a></b><br><em>Machine Learning, Robotics, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08111v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We introduce Hyper-Conditioned Neural Autoregressive Flow (HCNAF); a powerful universal distribution approximator designed to model arbitrarily complex conditional probability density functions. HCNAF consists of a neural-net based conditional autoregressive flow (AF) and a hyper-network that can take large conditions in non-autoregressive fashion and outputs the network parameters of the AF. …</summary><br> Like other flow models, HCNAF performs exact likelihood inference. We demonstrate the effectiveness and attributes of HCNAF, including its generalization capability over unseen conditions and show that HCNAF outperforms recent AF models in a conditional density estimation task for MNIST. We also show that HCNAF scales up to complex high-dimensional prediction problems of the magnitude of self-driving and that HCNAF yields a state-of-the-art performance in a public self-driving dataset.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Formal Languages and Automata Theory (cs.FL)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07915v1" style="color: #d9230f">Knowledge-Enhanced Attentive Learning for Answer Selection in Community Question Answering Systems</a></b><br><em>Artificial Intelligence, Computation and Language, Information Retrieval</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07915v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In the community question answering (CQA) system, the answer selection task aims to identify the best answer for a specific question, and thus is playing a key role in enhancing the service quality through recommending appropriate answers for new questions. Recent advances in CQA answer selection focus on enhancing the performance by incorporating the community information, particularly the expertise (previous answers) and authority (position in the social network) of an answerer. …</summary><br> However, existing approaches for incorporating such information are limited in (a) only considering either the expertise or the authority, but not both; (b) ignoring the domain knowledge to differentiate topics of previous answers; and (c) simply using the authority information to adjust the similarity score, instead of fully utilizing it in the process of measuring the similarity between segments of the question and the answer. We propose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which enhances the performance through (a) considering both the expertise and the authority of the answerer; (b) utilizing the human-labeled tags, the taxonomy of the tags, and the votes as the domain knowledge to infer the expertise of the answer; (c) using matrix decomposition of the social network (formed by following-relationship) to infer the authority of the answerer and incorporating such information in the process of evaluating the similarity between segments. Besides, for vertical community, we incorporate an external knowledge graph to capture more professional information for vertical CQA systems. Then we adopt the attention mechanism to integrate the analysis of the text of questions and answers and the aforementioned community information. Experiments with both vertical and general CQA sites demonstrate the superior performance of the proposed KAAS model.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Human-Computer Interaction (cs.HC)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07819v1" style="color: #d9230f">Angular Learning: Toward Discriminative Embedded Features</a></b><br><em>Computer Vision and Pattern Recognition, Machine Learning, Machine Learning</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07819v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The margin-based softmax loss functions greatly enhance intra-class compactness and perform well on the tasks of face recognition and object classification. Outperformance, however, depends on the careful hyperparameter selection. …</summary><br> Moreover, the hard angle restriction also increases the risk of overfitting. In this paper, angular loss suggested by maximizing the angular gradient to promote intra-class compactness avoids overfitting. Besides, our method has only one adjustable constant for intra-class compactness control. We define three metrics to measure inter-class separability and intra-class compactness. In experiments, we test our method, as well as other methods, on many well-known datasets. Experimental results reveal that our method has the superiority of accuracy improvement, discriminative information, and time-consumption.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Information Theory (cs.IT)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07829v1" style="color: #d9230f">Defects Mitigation in Resistive Crossbars for Analog Vector Matrix Multiplication</a></b><br><em>Emerging Technologies, Machine Learning</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07829v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>With storage and computation happening at the same place, computing in resistive crossbars minimizes data movement and avoids the memory bottleneck issue. It leads to ultra-high energy efficiency for data-intensive applications. …</summary><br> However, defects in crossbars severely affect computing accuracy. Existing solutions, including re-training with defects and redundant designs, but they have limitations in practical implementations. In this work, we introduce row shuffling and output compensation to mitigate defects without re-training or redundant resistive crossbars. We also analyzed the coupling effects of defects and circuit parasitics. Moreover, We study different combinations of methods to achieve the best trade-off between cost and performance. Our proposed methods could rescue up to 10% of defects in ResNet-20 application without performance degradation.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Multiagent Systems (cs.MA)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08138v1" style="color: #d9230f">Detection of a Source Code Plagiarism in a Student Programming Competition</a></b><br><em>Software Engineering</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08138v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The article presents a system for testing the independence of solutions to algorithmic problems sent by students as part of the student programming competition. First, the context was discussed, as well as the need to organize programming competitions resulting from this context. …</summary><br> Then, an algorithm was proposed to study the mutual similarity of source codes of programs sent as part of a programming competition. Since, after implementation, the algorithm was used in practice, examples of its application for detecting the plagiarism of source codes of solutions in two programming competitions conducted as part of classes on Algorithms and Numerical Methods were also presented. Finally, the effectiveness of the solutions used in the work was discussed.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Robotics (cs.RO)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08140v1" style="color: #d9230f">An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08140v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The goal of eXtreme Multi-label Learning (XML) is to design and learn a model that can automatically annotate a given data point with the most relevant subset of labels from an extremely large label set. Recently, many techniques have been proposed for XML that achieve reasonable performance on benchmark datasets. …</summary><br> Motivated by the complexities of these methods and their subsequent training requirements, in this paper we propose a simple baseline technique for this task. Precisely, we present a global feature embedding technique for XML that can easily scale to very large datasets containing millions of data points in very high-dimensional feature space, irrespective of number of samples and labels. Next we show how an ensemble of such global embeddings can be used to achieve further boost in prediction accuracies with only linear increase in training and prediction time. During testing, we assign the labels using a weighted k-nearest neighbour classifier in the embedding space. Experiments reveal that though conceptually simple, this technique achieves quite competitive results, and has training time of less than one minute using a single CPU core with 15.6 GB RAM even for large-scale datasets such as Amazon-3M.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="statistics">Statistics</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="4">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Machine Learning (stat.ML)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07882v1" style="color: #d9230f">Joint Interaction and Trajectory Prediction for Autonomous Driving using Graph Neural Networks</a></b><br><em>Machine Learning, Artificial Intelligence, Machine Learning</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07882v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this work, we aim to predict the future motion of vehicles in a traffic scene by explicitly modeling their pairwise interactions. Specifically, we propose a graph neural network that jointly predicts the discrete interaction modes and 5-second future trajectories for all agents in the scene. …</summary><br> Our model infers an interaction graph whose nodes are agents and whose edges capture the long-term interaction intents among the agents. In order to train the model to recognize known modes of interaction, we introduce an auto-labeling function to generate ground truth interaction labels. Using a large-scale real-world driving dataset, we demonstrate that jointly predicting the trajectories along with the explicit interaction types leads to significantly lower trajectory error than baseline methods. Finally, we show through simulation studies that the learned interaction modes are semantically meaningful.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08087v1" style="color: #d9230f">Substitutes for the non-existent square lattice designs for 36 varieties</a></b><br><em>Methodology, Combinatorics</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08087v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Square lattice designs are often used in trials of new varieties of various agricultural crops. However, there are no square lattice designs for 36 varieties in blocks of size six for four or more replicates. …</summary><br> Here we use three different approaches to construct designs for up to eight replicates. All the designs perform well in terms of giving a low average variance of variety contrasts. Supplementary materials are available online.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07820v1" style="color: #d9230f">Balancing the Tradeoff Between Clustering Value and Interpretability</a></b><br><em>Machine Learning, Data Structures and Algorithms, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07820v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Graph clustering groups entities – the vertices of a graph – based on their similarity, typically using a complex distance function over a large number of features. Successful integration of clustering approaches in automated decision-support systems hinges on the interpretability of the resulting clusters. …</summary><br> This paper addresses the problem of generating interpretable clusters, given features of interest that signify interpretability to an end-user, by optimizing interpretability in addition to common clustering objectives. We propose a <span class="math inline">\(\beta\)</span>-interpretable clustering algorithm that ensures that at least <span class="math inline">\(\beta\)</span> fraction of nodes in each cluster share the same feature value. The tunable parameter <span class="math inline">\(\beta\)</span> is user-specified. We also present a more efficient algorithm for scenarios with <span class="math inline">\(\beta\!=\!1\)</span> and analyze the theoretical guarantees of the two algorithms. Finally, we empirically demonstrate the benefits of our approaches in generating interpretable clusters using four real-world datasets. The interpretability of the clusters is complemented by generating simple explanations denoting the feature values of the nodes in the clusters, using frequent pattern mining.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08149v1" style="color: #d9230f">Estimation of Residential Radon Concentration in Pennsylvania Counties by Data Fusion</a></b><br><em>Applications, Methodology</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08149v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A data fusion method for the estimation of residential radon level distribution in any Pennsylvania county is proposed. The method is based on a multi-sample density ratio model with variable tilts and is applied to combined radon data from a reference county of interest and its neighboring counties. …</summary><br> Beaver county and its four immediate neighbors are taken as a case in point. The distribution of radon concentration is estimated in each of six periods, and then the analysis is repeated combining the data from all the periods to obtain estimates of Beaver threshold probabilities and the corresponding confidence intervals.
</details>
</td>
</tr>
<tr grouplength="3">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Methodology (stat.ME)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07775v1" style="color: #d9230f">Multiple Change Point Detection and Validation in Autoregressive Time Series Data</a></b><br><em>Computation, Methodology</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07775v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>It is quite common that the structure of a time series changes abruptly. Identifying these change points and describing the model structure in the segments between these change points is of interest. …</summary><br> In this paper, time series data is modelled assuming each segment is an autoregressive time series with possibly different autoregressive parameters. This is achieved using two main steps. The first step is to use a likelihood ratio scan based estimation technique to identify these potential change points to segment the time series. Once these potential change points are identified, modified parametric spectral discrimination tests are used to validate the proposed segments. A numerical study is conducted to demonstrate the performance of the proposed method across various scenarios and compared against other contemporary techniques.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08103v1" style="color: #d9230f">A Finite-Sample Deviation Bound for Stable Autoregressive Processes</a></b><br><em>Machine Learning, Machine Learning, Signal Processing, Statistics Theory, Statistics Theory</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08103v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this paper, we study non-asymptotic deviation bounds of the least squares estimator in Gaussian AR(<span class="math inline">\(n\)</span>) processes. By relying on martingale concentration inequalities and a tail-bound for <span class="math inline">\(\chi^2\)</span> distributed variables, we provide a concentration bound for the sample covariance matrix of the process output. …</summary><br> With this, we present a problem-dependent finite-time bound on the deviation probability of any fixed linear combination of the estimated parameters of the AR<span class="math inline">\((n)\)</span> process. We discuss extensions and limitations of our approach.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08050v1" style="color: #d9230f">A nonparametric Bayesian approach to simultaneous subject and cell heterogeneity discovery for single cell RNA-seq data</a></b><br><em>Methodology, Applications</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.08050v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The advent of the single cell sequencing era opens new avenues for the personalized treatment. The first but important step is to discover the subject heterogeneity at the single cell resolution. …</summary><br> In this article, we address the two-level-clustering problem of simultaneous subject subgroup discovery (subject level) and cell type detection (cell level) based on the scRNA-seq data from multiple subjects. However, the current statistical approaches either cluster cells without considering the subject heterogeneity or group subjects not using the single-cell information. To overcome the challenges and fill the gap between cell clustering and subject grouping, we develop a solid nonparametric Bayesian model SCSC (Subject and Cell clustering for Single-Cell expression data) to achieve subject and cell grouping at the same time. SCSC does not need to prespecify the subject subgroup number or the cell type number, automatically induces subject subgroup structures and matches cell types across subjects, and directly models the scRNA-seq raw count data by deliberately considering the data’s dropouts, library sizes, and over-dispersion. A computationally efficient blocked Gibbs sampler is proposed for the posterior inference. The simulation and the application to a multi-subject iPSC scRNA-seq dataset validate the function of SCSC to discover subject and cell heterogeneity.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Applications (stat.AP)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08165v1" style="color: #d9230f">Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for Python, C++, and soon more</a></b><br><em>Machine Learning, Machine Learning</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08165v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Cyanure is an open-source C++ software package with a Python interface. The goal of Cyanure is to provide state-of-the-art solvers for learning linear models, based on stochastic variance-reduced stochastic optimization with acceleration mechanisms. …</summary><br> Cyanure can handle a large variety of loss functions (logistic, square, squared hinge, multinomial logistic) and regularization functions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It provides a simple Python API, which is very close to that of scikit-learn, which should be extended to other languages such as R or Matlab in a near future.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Computation (stat.CO)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08162v1" style="color: #d9230f">Optimality of Observed Information Adaptive Designs in Linear Models</a></b><br><em>Methodology</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08162v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>This work considers experimental design in linear models with additive errors. A traditional objective in design is to minimize the variance of the estimates of the model parameters. …</summary><br> The optimal design, which is found by minimizing a convex function of the expected Fisher information, accomplishes this objective, approximately. The inverse of expected Fisher information is asymptotically equivalent to the variance of the maximum likelihood estimate. It is often remarked that observed Fisher information is a better measure of the variance of the maximum likelihood estimate than the expected Fisher information [Efron and Hinkley (1978)]. However, unlike expected Fisher information, observed Fisher information depends on the observed data and cannot be used to design an experiment in advance of data collection. In a sequential experiment the observed Fisher information from past observations is available to incorporate into the design of the current observation. In this work an adaptive design that incorporates observed Fisher information is proposed. It is shown that this proposed design is optimal, at the limit, with respect to inference and conditional mean square error. In a simulation study the proposed adaptive design performs nearly uniformly better than the optimal design.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="elec.-eng.-and-systems-science">Elec. Eng. and Systems Science</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="4">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Image and Video Processing (eess.IV)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08057v1" style="color: #d9230f">A Novel Self-Organizing PID Approach for Controlling Mobile Robot Locomotion</a></b><br><em>Robotics, Systems and Control</em>. 6 authors. <a href="http://arxiv.org/pdf/1912.08057v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID) control system is proposed in this paper. The proposed system consists of a pair of control and reference models, both of which are implemented by a first-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. …</summary><br> The SOF-PID controller self-organizes and self-updates the structures and meta-parameters of both the control and reference models during the control process “on the fly”. This gives the SOF-PID control system the capability of quickly adapting to entirely new operating environments without a full re-training. Moreover, the SOF-PID control system is free from user- and problem-specific parameters, and the uniform stability of the SOF-PID control system is theoretically guaranteed. Simulations and real-world experiments with mobile robots demonstrate the effectiveness and validity of the proposed SOF-PID control system.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08178v1" style="color: #d9230f">AeroRIT: A New Scene for Hyperspectral Image Analysis</a></b><br><em>Image and Video Processing, Computer Vision and Pattern Recognition</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08178v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Hyperspectral imagery oriented research like image super-resolution and image fusion is often conducted on open source datasets captured via point and shoot camera setups (ICVL, CAVE) that have high signal to noise ratio. In contrast, spectral images captured from aircrafts have low spatial resolution and suffer from higher noise interference due to factors pertaining to atmospheric conditions. …</summary><br> This leads to challenges in extracting contextual information from the captured data as convolutional neural networks are very noise-sensitive and slight atmospheric changes can often lead to a large distribution spread in spectral values overlooking the same object. To understand the challenges faced with aerial spectral data, we collect and label a flight line over the university campus, AeroRIT, and explore the task of semantic segmentation. To the best of our knowledge, this is the first comprehensive large-scale hyperspectral scene with nearly seven million semantic annotations for identifying cars, roads and buildings. We compare the performance of three popular architectures - SegNet, U-Net and Res-U-Net, for scene understanding and object identification. To date, aerial hyperspectral image analysis has been restricted to small datasets with limited train/test splits capabilities. We believe AeroRIT will help advance the research in the field with a more complex object distribution.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08002v1" style="color: #d9230f">Adaptive Densely Connected Super-Resolution Reconstruction</a></b><br><em>Image and Video Processing, Computer Vision and Pattern Recognition</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08002v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>For a better performance in single image super-resolution(SISR), we present an image super-resolution algorithm based on adaptive dense connection (ADCSR). The algorithm is divided into two parts: BODY and SKIP. …</summary><br> BODY improves the utilization of convolution features through adaptive dense connections. Also, we develop an adaptive sub-pixel reconstruction layer (AFSL) to reconstruct the features of the BODY output. We pre-trained SKIP to make BODY focus on high-frequency feature learning. The comparison of PSNR, SSIM, and visual effects verify the superiority of our method to the state-of-the-art algorithms.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08142v1" style="color: #d9230f">Causality matters in medical imaging</a></b><br><em>Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08142v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>This article discusses how the language of causality can shed new light on the major challenges in machine learning for medical imaging: 1) data scarcity, which is the limited availability of high-quality annotations, and 2) data mismatch, whereby a trained algorithm may fail to generalize in clinical practice. Looking at these challenges through the lens of causality allows decisions about data collection, annotation procedures, and learning strategies to be made (and scrutinized) more transparently. …</summary><br> We discuss how causal relationships between images and annotations can not only have profound effects on the performance of predictive models, but may even dictate which learning strategies should be considered in the first place. For example, we conclude that semi-supervision may be unsuitable for image segmentation—one of the possibly surprising insights from our causal analysis, which is illustrated with representative real-world examples of computer-aided diagnosis (skin lesion classification in dermatology) and radiotherapy (automated contouring of tumours). We highlight that being aware of and accounting for the causal relationships in medical imaging data is important for the safe development of machine learning and essential for regulation and responsible reporting. To facilitate this we provide step-by-step recommendations for future studies.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>eess.SY (eess.SY)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08180v1" style="color: #d9230f">Deep Radar Waveform Design for Efficient Automotive Radar Sensing</a></b><br><em>Signal Processing, Machine Learning, Machine Learning</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.08180v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. …</summary><br> In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a well-known unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Signal Processing (eess.SP)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08167v1" style="color: #d9230f">Fast Glioblastoma Detection in Fluid-attenuated inversion recovery (FLAIR) images by Topological Explainable Automatic Machine Learning</a></b><br><em>Image and Video Processing, Computer Vision and Pattern Recognition, Quantitative Methods</em>. 1 authors. <a href="http://arxiv.org/pdf/1912.08167v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Glioblastoma multiforme (GBM) is a fast-growing and highly invasive brain tumor, it tends to occur in adults between the ages of 45 and 70 and it accounts for 52 percent of all primary brain tumors. Usually, GBMs are detected by magnetic resonance images (MRI). …</summary><br> Among MRI images, Fluid-attenuated inversion recovery (FLAIR) sequence produces high quality digital tumor representation. This sequence is very sensitive to pathology and makes the differentiation between cerebrospinal fluid (CSF) and an abnormality much easier. Fast detection and segmentation techniques are needed for overcoming subjective medical doctors (MDs) judgment. In this work, a new methodology for fast detection and segmentation of GBM on FLAIR images is presented. The methodology leverages topological data analysis, textural features and interpretable machine learning algorithm, it was evaluated on a public available dataset. The machine learning classifier uses only eight input numerical features and it reaches up to the 97% of accuracy on the detection task and up to 95% of accuracy on the segmentation task. Tools from information theory were used for interpreting, in a human readable format, what are the main numerical characteristics of an image to be classified ill or healthy.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="mathematics">Mathematics</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="4">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Statistics Theory (math.ST)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08112v1" style="color: #d9230f">A learning-based algorithm to quickly compute good primal solutions for Stochastic Integer Programs</a></b><br><em>Optimization and Control, Machine Learning</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08112v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We propose a novel approach using supervised learning to obtain near-optimal primal solutions for two-stage stochastic integer programming (2SIP) problems with constraints in the first and second stages. The goal of the algorithm is to predict a “representative scenario” (RS) for the problem such that, deterministically solving the 2SIP with the random realization equal to the RS, gives a near-optimal solution to the original 2SIP. …</summary><br> Predicting an RS, instead of directly predicting a solution ensures first-stage feasibility of the solution. If the problem is known to have complete recourse, second-stage feasibility is also guaranteed. For computational testing, we learn to find an RS for a two-stage stochastic facility location problem with integer variables and linear constraints in both stages and consistently provide near-optimal solutions. Our computing times are very competitive with those of general-purpose integer programming solvers to achieve a similar solution quality.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08003v1" style="color: #d9230f">Changing reference measure in Bayes spaces with applications to functional data analysis</a></b><br><em>Statistics Theory, Statistics Theory</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.08003v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Probability density functions (PDFs) can be understood as continuous compositions by the theory of Bayes spaces. The origin of a Bayes space is determined by a given reference measure. …</summary><br> This can be easily changed through the well-known chain rule which has an impact on the geometry of the Bayes space. This work provides a mathematical framework for setting a reference measure. It is used to develop a weighting scheme on the bounded domain of distributional data. The impact on statistical analysis is shown from the perspective of simplicial functional principal component analysis. Moreover, a novel centered log-ratio transformation is proposed to map a weighted Bayes spaces into an unweighted <span class="math inline">\(L^2\)</span> space, enabling to use most tools developed in functional data analysis (e.g. clustering, regression analysis, etc.) while accounting for the weighting strategy. The potential of our proposal is shown through simulation and on a real case study using Italian income data.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08177v1" style="color: #d9230f">Lift &amp; Learn: Physics-informed machine learning for large-scale nonlinear dynamical systems</a></b><br><em>Numerical Analysis, Machine Learning, Numerical Analysis</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08177v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We present Lift &amp; Learn, a physics-informed method for learning low-dimensional models for large-scale dynamical systems. The method exploits knowledge of a system’s governing equations to identify a coordinate transformation in which the system dynamics have quadratic structure. …</summary><br> This transformation is called a lifting map because it often adds auxiliary variables to the system state. The lifting map is applied to data obtained by evaluating a model for the original nonlinear system. This lifted data is projected onto its leading principal components, and low-dimensional linear and quadratic matrix operators are fit to the lifted reduced data using a least-squares operator inference procedure. Analysis of our method shows that the Lift &amp; Learn models are able to capture the system physics in the lifted coordinates at least as accurately as traditional intrusive model reduction approaches. This preservation of system physics makes the Lift &amp; Learn models robust to changes in inputs. Numerical experiments on the FitzHugh-Nagumo neuron activation model and the compressible Euler equations demonstrate the generalizability of our model.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07967v1" style="color: #d9230f">Weibull analysis with sequential order statistics under a power trend model for hazard rates</a></b><br><em>Statistics Theory, Methodology, Statistics Theory</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07967v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In engineering systems, it is usually assumed that lifetimes of components are independent and identically distributed (iid). But, the failure of a component results in a higher load on the remaining components and hence causes the distribution of the surviving components change. …</summary><br> For modeling this kind of systems, the theory of sequential order statistics (SOS) can be used. Assuming Weibull distribution for lifetimes of components and conditionally proportional hazard rates model as a special case of the SOS theory, the maximum likelihood estimates of the unknown parameters are obtained in different cases. A new model, denoted by PTCPHM, as a generalization of the iid case is proposed, and then statistical inferential methods including point and interval estimation as well as hypothesis tests under PTCPHM are then developed. Finally, a real data on failure times of aircraft components, due to Mann and Fertig (1973), is analyzed to illustrate the model and inferential methods developed here.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Numerical Analysis (math.NA)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07948v1" style="color: #d9230f">Jackknife covariance matrix estimation for observations from mixture</a></b><br><em>Statistics Theory, Statistics Theory</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07948v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A general jackknife estimator for the asymptotic covariance of moment estimators is considered in the case when the sample is taken from a mixture with varying concentrations of components. Consistency of the estimator is demonstrated. …</summary><br> A fast algorithm for its calculation is described. The estimator is applied to construction of confidence sets for regression parameters in the linear regression with errors in variables. An application to sociological data analysis is considered.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Optimization and Control (math.OC)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07879v1" style="color: #d9230f">Nonparametric density estimation for intentionally corrupted functional data</a></b><br><em>Statistics Theory, Statistics Theory</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07879v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We consider statistical models where functional data are artificially contaminated by independent Wiener processes in order to satisfy privacy constraints. We show that the corrupted observations have a Wiener density which determines the distribution of the original functional random variables, masked near the origin, uniquely, and we construct a nonparametric estimator of that density. …</summary><br> We derive an upper bound for its mean integrated squared error which has a polynomial convergence rate, and we establish an asymptotic lower bound on the minimax convergence rates which is close to the rate attained by our estimator. Our estimator requires the choice of a basis and of two smoothing parameters. We propose data-driven ways of choosing them and prove that the asymptotic quality of our estimator is not significantly affected by the empirical parameter selection. We examine the numerical performance of our method via simulated examples.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="physics">Physics</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="4">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Computational Physics (physics.comp-ph)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07921v1" style="color: #d9230f">Octopus, a computational framework for exploring light-driven phenomena and quantum dynamics in extended and finite systems</a></b><br><em>Computational Physics</em>. 34 authors. <a href="http://arxiv.org/pdf/1912.07921v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Over the last years extraordinary advances in experimental and theoretical tools have allowed us to monitor and control matter at short time and atomic scales with a high-degree of precision. An appealing and challenging route towards engineering materials with tailored properties is to find ways to design or selectively manipulate materials, especially at the quantum level. …</summary><br> To this end, having a state-of-the-art ab initio computer simulation tool that enables a reliable and accurate simulation of light-induced changes in the physical and chemical properties of complex systems is of utmost importance. The first principles real-space-based Octopus project was born with that idea in mind, providing an unique framework allowing to describe non-equilibrium phenomena in molecular complexes, low dimensional materials, and extended systems by accounting for electronic, ionic, and photon quantum mechanical effects within a generalized time-dependent density functional theory framework. The present article aims to present the new features that have been implemented over the last few years, including technical developments related to performance and massive parallelism. We also describe the major theoretical developments to address ultrafast light-driven processes, like the new theoretical framework of quantum electrodynamics density-functional formalism (QEDFT) for the description of novel light-matter hybrid states. Those advances, and other being released soon as part of the Octopus package, will enable the scientific community to simulate and characterize spatial and time-resolved spectroscopies, ultrafast phenomena in molecules and materials, and new emergent states of matter (QED-materials).
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07893v1" style="color: #d9230f">Spinal compressive forces in adolescent idiopathic scoliosis with and without carrying loads: a musculoskeletal modeling study</a></b><br><em>Medical Physics, Biological Physics, Quantitative Methods, Tissues and Organs</em>. 7 authors. <a href="http://arxiv.org/pdf/1912.07893v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The pathogenesis of adolescent idiopathic scoliosis (AIS) remains poorly understood and biomechanical data are limited. A deeper insight into spinal loading could provide valuable information for the improvement of current treatment strategies. …</summary><br> This work therefore aimed at using subject-specific musculoskeletal full-body models of patients with AIS to predict segmental compressive forces around the curve apex and to investigate how these forces are affected by simulated load carrying. Models were created based on spatially calibrated biplanar radiographic images from 24 patients with mild to moderate AIS and validated by comparing predictions of paravertebral muscle activity with reported values from in vivo studies. Spinal compressive forces were predicted during unloaded upright standing as well as upright standing with external loads of 10%, 15% and 20% of body weight (BW) applied to the scapulae to simulate carrying a backpack in the regular way, in front of the body and over both shoulders. The validation studies showed higher convex muscle activity, which was comparable to the literature. The implementation of spinal deformity resulted in a 10% increase of compressive force at the curve apex during unloaded upright standing. Apical compressive forces further increased by 50-62%, 77-94% and 103-128% for 10%, 15% and 20% BW loads, respectively. Moreover, load-dependent compressive force increases were the lowest in the regular backpack and the highest in the frontpack and convex conditions. The predictions indicated increased segmental compressive forces during unloaded standing, which could be ascribed to the scoliotic deformation. When carrying loads, compressive forces further increased depending on the carrying mode and the weight of the load. These results can be used as a basis for further studies investigating segmental loading in AIS patients during functional activities.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07815v1" style="color: #d9230f">Large-scale simulation of shallow water waves with computation only on small staggered patches</a></b><br><em>Computational Physics, Numerical Analysis, Dynamical Systems, Numerical Analysis, Pattern Formation and Solitons</em>. 5 authors. <a href="http://arxiv.org/pdf/1912.07815v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The multiscale patch scheme is built from given small micro-scale simulations of complicated physical processes to empower large macro-scale simulations. By coupling small patches of simulations over unsimulated spatial gaps, large savings in computational time are possible. …</summary><br> Here we discuss generalising the patch scheme to the case of wave systems on staggered grids in 2D space. Classic macro-scale interpolation provides a generic coupling between patches that achieves arbitrarily high order consistency between the emergent macro-scale simulation and the underlying micro-scale dynamics. Eigen-analysis indicates that the resultant scheme empowers feasible computation of large macro-scale simulations of wave systems even with complicated underlying physics. As examples we use the scheme to simulate some wave scenarios via a turbulent shallow water model.
</details>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07889v1" style="color: #d9230f">Upper limit to the photovoltaic efficiency of imperfect crystals</a></b><br><em>Computational Physics, Materials Science</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07889v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>The Shockley-Queisser (SQ) limit provides a convenient metric for predicting light-to-electricity conversion efficiency of a solar cell based on the band gap of the light-absorbing layer. In reality, few materials approach this radiative limit. …</summary><br> We develop a formalism and a computational method to predict the maximum photovoltaic efficiency of imperfect crystals from first principles. Our scheme includes equilibrium populations of native defects, their carrier-capture coefficients, and the associated recombination rates. When applied to kesterite solar cells, we reveal an intrinsic limit of 20% for Cu2ZnSnSe4, which falls far below the SQ limit of 32%. The effects of atomic substitution and extrinsic doping are studied, leading to pathways for an enhanced efficiency of 31%. This approach can be applied to support targeted-materials selection for future solar-energy technologies.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Data Analysis, Statistics and Probability (physics.data-an)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07954v1" style="color: #d9230f">Search in a fitness landscape: How to assess the difficulty of a search problem</a></b><br><em>Data Analysis, Statistics and Probability, Physics and Society</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.07954v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Computational modeling is widely used to study how individuals and organizations search and solve problems in fields such as economics, management, cultural evolution, and computer science. We argue that current computational modelling research on problem-solving needs to address several fundamental issues in order to generate more meaningful and falsifiable contributions. …</summary><br> Based on comparative simulations and a new type of visualization of how to assess the nature of the fitness landscape, we address two key assumptions that approaches such as the NK framework rely on: that the NK captures the continuum of complexity of empirical fitness landscapes, and that search behavior is a distinct component, independent from the topology of the fitness landscape. We show the limitations of the most common approach to conceptualize how complex, or rugged, a landscape is, as well as how the nature of the fitness landscape is fundamentally intertwined with search behavior. Finally, we outline broader implications for how to stimulate problem-solving.
</details>
</td>
</tr>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Medical Physics (physics.med-ph)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07982v1" style="color: #d9230f">A multiscale discrete velocity method for model kinetic equations</a></b><br><em>Computational Physics, Numerical Analysis, Numerical Analysis, Fluid Dynamics</em>. 3 authors. <a href="http://arxiv.org/pdf/1912.07982v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>In this paper, authors focus effort on improving the conventional discrete velocity method (DVM) into a multiscale scheme in finite volume framework for gas flow in all flow regimes. Unlike the typical multiscale kinetic methods unified gas-kinetic scheme (UGKS) and discrete unified gas-kinetic scheme (DUGKS), which concentrate on the evolution of the distribution function at the cell interface, in the present scheme the flux for macroscopic variables is split into the equilibrium part and the nonequilibrium part, and the nonequilibrium flux is calculated by integrating the discrete distribution function at the cell center, which overcomes the excess numerical dissipation of the conventional DVM in the continuum flow regime. …</summary><br> Afterwards, the macroscopic variables are finally updated by simply integrating the discrete distribution function at the cell center, or by a blend of the increments based on the macroscopic and the microscopic systems, and the multiscale property is achieved. Several test cases, involving unsteady, steady, high speed, low speed gas flows in all flow regimes, have been performed, demonstrating the good performance of the multiscale DVM from free molecule to continuum Navier-Stokes solutions and the multiscale property of the scheme is proved.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="condensed-matter">Condensed Matter</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Materials Science (cond-mat.mtrl-sci)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08025v1" style="color: #d9230f">Antiferromagnetic CuMnAs: Ab initio description of finite temperature magnetism and resistivity</a></b><br><em>Materials Science, Computational Physics</em>. 4 authors. <a href="http://arxiv.org/pdf/1912.08025v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>Noncollinear magnetic moments in antiferromagnets (AFM) lead to a complex behavior of electrical transport, even to a decreasing resistivity due to an increasing temperature. Proper treatment of such phenomena is required for understanding AFM systems at finite temperatures; however first-principles description of these effects is complicated. …</summary><br> With ab initio techniques, we investigate three numerically feasible models of spin fluctuations (magnons) influencing the transport in AFM CuMnAs. We numerically justified a fully relativistic collinear disordered local moment approach, whose uncompensated generalization reliably describes spin fluctuations, including anisotropy of electrical transport, in a wide temperature range. A saturation or a decrease of resistivity caused by magnons, phonons, and their combination (above approx. 400 K) was observed and explained by changes in electronic structure. Within the coherent potential approximation, our finite-temperature approaches may be applied also to systems with impurities, which are found to have a large impact not only on residual resistivity, but also on canting of magnetic moments from the AFM to the ferromagnetic state.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="quantitative-biology">Quantitative Biology</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Biomolecules (q-bio.BM)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.08141v1" style="color: #d9230f">Performance of regression models as a function of experiment noise</a></b><br><em>Biomolecules, Machine Learning</em>. 8 authors. <a href="http://arxiv.org/pdf/1912.08141v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>A challenge in developing machine learning regression models is that it is difficult to know whether maximal performance has been reached on a particular dataset, or whether further model improvement is possible. In biology this problem is particularly pronounced as sample labels are typically obtained through experiments and therefore have experiment noise associated with them. …</summary><br> Such label noise puts a fundamental limit to the performance attainable by regression models. We address this challenge by deriving a theoretical upper bound for the coefficient of determination (R2) for regression models. This theoretical upper bound depends only on the noise associated with sample labels in a dataset as well as the label variance. The upper bound estimate was validated via Monte Carlo simulations and then used as a tool to bootstrap performance of regression models trained on biological datasets, including protein sequence data, transcriptomic data, and genomic data. Although we study biological datasets in this work, the new upper bound estimates will hold true for regression models from any research field or application area where sample labels are associated with noise.
</details>
</td>
</tr>
</tbody>
</table>
<h3 id="quantum-physics">Quantum Physics</h3>
<table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr grouplength="1">
<td colspan="1" style="background-color: #666; color: #fff;">
<strong>Quantum Physics (quant-ph)</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
<b><a href="http://arxiv.org/abs/1912.07904v1" style="color: #d9230f">QuESTlink – Mathematica embiggened by a hardware-optimised quantum emulator</a></b><br><em>Quantum Physics, Computational Physics</em>. 2 authors. <a href="http://arxiv.org/pdf/1912.07904v1" style="color: #d9230f;
    text-decoration: none;">pdf</a><br>
<details>
<summary>We introduce QuESTlink, pronounced “quest link”, an open-source Mathematica package which efficiently emulates quantum computers. By integrating with the Quantum Exact Simulation Toolkit (QuEST), QuESTlink offers a high-level, expressive and usable interface to a high-performance, hardware-accelerated emulator. …</summary><br> Requiring no installation, QuESTlink streamlines the powerful analysis capabilities of Mathematica into the study of quantum systems, even utilising remote multicore and GPU hardware. We demonstrate the use of QuESTlink to concisely and efficiently simulate several quantum algorithms, and present some comparative benchmarking against core QuEST.
</details>
</td>
</tr>
</tbody>
</table>
</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
